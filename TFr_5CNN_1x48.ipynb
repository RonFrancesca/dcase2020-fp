{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TFr_5CNN_1x48_mse_dropCNNRNN_AR_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJRz4TmfGB0B",
        "colab_type": "text"
      },
      "source": [
        "##DCASE Challenge 2020, Task 3\n",
        "\n",
        "The methodology proposed in this report is based on Adavanneet et al. SELDNet [1], including some of the adopted additions in the baseline algorithm of the DCASE 2020 Task 3, such as the use of log-mel  spectral  coefficients  and  acoustic  intensity  vector  for  the FOA format.  However, the system proposed in this notwbook differs from the baseline in different points such as (i) network architecture and (ii) training loss functions. Regarding (i), the network has 2 convolutional layers more, increasing from 3 to 5 convolutional layers. Furthermore the receptive field has been expanded using dense rectangular filters (instead of squared ones) in order to make the network able to recognize frequency features relevant for the task. With regard to (ii), we used the same loss functions proposed in [1].  Binary cross-entropy loss is used for Sound Event Detection (SED) prediction task while mean square error (MSE) loss is used for Direction-Of-Arrival (DOA) estimation.\n",
        "\n",
        "[1]: Adavanne, Sharath, et al. \"Sound event localization and detection of overlapping sources using convolutional recurrent neural networks.\" IEEE Journal of Selected Topics in Signal Processing 13.1 (2018): 34-48.\n",
        "\n",
        "Please, follow the instructions and change the folder paths with the ones related to your machine or drive. \n",
        "The paths needed to be changed are marked with a TODO command. \n",
        "\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_Or5LtqG3QS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing the right version of tensorflow (we are suing tensorflow 2)\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I3-jaV3G3xp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbac4a9a-6f0e-4f77-9b09-4f923ad60d61"
      },
      "source": [
        "#making sure the tensorflow version is correct  \n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pScgmzzNG5US",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "6c660e63-3aa7-4ed0-b78e-f45e3c0734cd"
      },
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6Vp5_CNGdW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing all the libraries we will need \n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plot\n",
        "import time"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBKn5fMyHd10",
        "colab_type": "text"
      },
      "source": [
        "## Parameters definition\n",
        "\n",
        "All the paramaters needed to properly configure the notebook and run the algorithm are defined in the following cell. \n",
        "\n",
        "Please, change the folder paths with the ones related to you machine and/or drive. The paths that need to be changed are marked with a TODO command. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "275oeMl8XAP2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "25801ab5-05a1-4077-c470-141baca8b544"
      },
      "source": [
        "# Parameters used in the feature extraction, neural network model, and training the SELDnet can be changed here.\n",
        "# different cases to select different dataset type\n",
        "case = 1\n",
        "\n",
        "# DATASET LOADING PARAMETERS\n",
        "# 'dev' - development or 'eval' - evaluation dataset\n",
        "mode='eval'\n",
        "# 'foa' - ambisonic or 'mic' - microphone signals                                               \n",
        "dataset='foa' \n",
        "\n",
        "# quick test a nd data augmentation flag\n",
        "quick_test=False     \n",
        "\n",
        "#dataset name could be 'daa or 'dar' or 'base'\n",
        "dataset_name = 'dataset-eval' \n",
        "dataset_aug = False if dataset == 'mic' else True\n",
        "\n",
        "#network could be keras or TF\n",
        "network = 'TFr-5CNN-1x48' \n",
        "#BASE PATH\n",
        "network_name = network + '-{}'.format(dataset)\n",
        "#TODO: Change it with with proper path in your machine\n",
        "base_dir = '/content/drive/My Drive/Dataset-FP/'\n",
        "\n",
        "# INPUT PATH\n",
        "# Base folder containing the foa/mic and metadata folders\n",
        "dataset_dir = \"\".join([base_dir, dataset_name])\n",
        "# Directory where to extract features and labels    \n",
        "#TODO: Change it with with proper path in your machine\n",
        "feat_label_dir= os.path.join(dataset_dir, 'feat_label-AR/')  \n",
        "\n",
        "# OUTPUT PATH\n",
        "output_dir = \"\".join([base_dir, dataset_name, '-output/', network_name])\n",
        "# Dumps the trained models and training curves in this folder\n",
        "# If true, dumps the results recording-wise in 'dcase_dir' path.          \n",
        "dcase_output=True \n",
        "# Train for maximum epochs                                 \n",
        "nb_epochs=50                                \n",
        "                                                                                                                                                                                  \n",
        "\n",
        "#FEATURE PARAMS\n",
        "fs=24000\n",
        "hop_len_s=0.02\n",
        "label_hop_len_s=0.1\n",
        "max_audio_len_s=60\n",
        "nb_mel_bins=64\n",
        "\n",
        "# DNN MODEL PARAMETERS\n",
        "# Feature sequence length\n",
        "label_sequence_length=60\n",
        "# Batch size                                  \n",
        "batch_size=128\n",
        "# Dropout rate, constant for all layers                                           \n",
        "dropout_rate_cnn=0.2\n",
        "dropout_rate_rnn = 0.2\n",
        "dropout_rate = 0\n",
        "# Number of CNN nodes, constant for each layer                                            \n",
        "nb_cnn2d_filt=64                                           \n",
        "\n",
        "# CNN frequency pooling, length of list = number of CNN layers, list value = pooling per layer\n",
        "f_pool_size=[2, 2, 2, 2, 2]                                      \n",
        "\n",
        "# RNN contents, length of list = number of layers, list value = number of nodes\n",
        "rnn_size=[128, 128] \n",
        "# FNN contents, length of list = number of layers, list value = number of nodes                                      \n",
        "fnn_size=[128]\n",
        "# [sed, doa] weight for scaling the DNN outputs                                           \n",
        "loss_weights=[1., 1000.] \n",
        "# Number of epochs per fit                                               \n",
        "epochs_per_fit=5\n",
        "# supports: mse, masked_mse. mse- original seld approach; masked_mse - dcase 2020 approach                                           \n",
        "doa_objective='mse'     \n",
        "\n",
        "        \n",
        "#METRIC PARAMETERS\n",
        "lad_doa_thresh=20\n",
        "sed_threshold=0.5\n",
        "nb_classes = 14\n",
        "\n",
        "feature_label_resolution = int(label_hop_len_s // hop_len_s)\n",
        "feature_sequence_length = label_sequence_length * feature_label_resolution\n",
        "# CNN time pooling\n",
        "t_pool_size = [feature_label_resolution, 1, 1, 1, 1]\n",
        "# Stop training if patience is reached       \n",
        "patience = 4                \n",
        "\n",
        "unique_classes = {\n",
        "            'alarm': 0,\n",
        "            'baby': 1,\n",
        "            'crash': 2,\n",
        "            'dog': 3,\n",
        "            'engine': 4,\n",
        "            'female_scream': 5,\n",
        "            'female_speech': 6,\n",
        "            'fire': 7,\n",
        "            'footsteps': 8,\n",
        "            'knock': 9,\n",
        "            'male_scream': 10,\n",
        "            'male_speech': 11,\n",
        "            'phone': 12,\n",
        "            'piano': 13\n",
        "        }\n",
        "\n",
        "\n",
        "    # ########### User defined parameters ##############\n",
        "    # different user parameters so to set dev or eval mode and foa or mic dataset, or quick test \n",
        "if case == 1:\n",
        "  print(\"USING DEFAULT PARAMETERS\\n\")\n",
        "\n",
        "elif case == 2:\n",
        "  mode = 'dev'\n",
        "  dataset = 'mic'\n",
        "\n",
        "elif case == 3:\n",
        "   mode = 'eval'\n",
        "   dataset = 'mic'\n",
        "\n",
        "elif case == 4:\n",
        "    mode = 'dev'\n",
        "    dataset = 'foa'\n",
        "\n",
        "elif case == 5:\n",
        "    mode = 'eval'\n",
        "    dataset = 'foa'\n",
        "\n",
        "elif case == 999:\n",
        "      print(\"QUICK TEST MODE\\n\")\n",
        "      quick_test = True\n",
        "      epochs_per_fit = 1\n",
        "\n",
        "else:\n",
        "    print('ERROR: unknown argument {}'.format(case))\n",
        "    exit()\n",
        "       "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "USING DEFAULT PARAMETERS\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb2Xa7_TOcX2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#utils function\n",
        "def create_folder(folder_name):\n",
        "    if not os.path.exists(folder_name):\n",
        "        print('{} folder does not exist, creating it.'.format(folder_name))\n",
        "        os.makedirs(folder_name)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diMFE0CcN7qT",
        "colab_type": "text"
      },
      "source": [
        "## Feature class\n",
        "\n",
        "The next cell implements and defines the feature extraction class, together with the functions needed to get and retrieve information related to feature extraction and data input features. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFzgazc7N5RT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Contains routines for labels creation, features extraction and normalization\n",
        "import librosa\n",
        "import math\n",
        "import random\n",
        "\n",
        "\n",
        "def nCr(n, r):\n",
        "    return math.factorial(n) // math.factorial(r) // math.factorial(n-r)\n",
        "\n",
        "\n",
        "class FeatureClass:\n",
        "    def __init__(self, is_eval=False):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        --------------\n",
        "        :param params: parameters dictionary\n",
        "        :param is_eval: if True, does not load dataset labels.\n",
        "        \"\"\"\n",
        "\n",
        "\n",
        "        # Input directories\n",
        "        self._feat_label_dir = feat_label_dir\n",
        "        self._dataset_dir = dataset_dir\n",
        "        self._dataset_combination = '{}_{}'.format(dataset, 'eval' if is_eval else 'dev')\n",
        "        self._aud_dir = os.path.join(self._dataset_dir, self._dataset_combination)\n",
        "\n",
        "        self._desc_dir = None if is_eval else os.path.join(self._dataset_dir, 'metadata_dev')\n",
        "\n",
        "        # Output directories\n",
        "        self._label_dir = None\n",
        "        self._feat_dir = None\n",
        "        self._feat_dir_norm = None\n",
        "\n",
        "        # Local parameters\n",
        "        self._is_eval = is_eval\n",
        "\n",
        "        self._fs = fs\n",
        "        self._hop_len_s = hop_len_s\n",
        "        self._hop_len = int(self._fs * self._hop_len_s)\n",
        "\n",
        "        self._label_hop_len_s = label_hop_len_s\n",
        "        self._label_hop_len = int(self._fs * self._label_hop_len_s)\n",
        "        self._label_frame_res = self._fs / float(self._label_hop_len)\n",
        "        self._nb_label_frames_1s = int(self._label_frame_res)\n",
        "\n",
        "        self._win_len = 2 * self._hop_len\n",
        "        self._nfft = self._next_greater_power_of_2(self._win_len)\n",
        "        self._nb_mel_bins = nb_mel_bins\n",
        "        self._mel_wts = librosa.filters.mel(sr=self._fs, n_fft=self._nfft, n_mels=self._nb_mel_bins).T\n",
        "\n",
        "        self._dataset = dataset\n",
        "        self._eps = 1e-8\n",
        "        self._nb_channels = 4\n",
        "\n",
        "        # Sound event classes dictionary\n",
        "        self._unique_classes = unique_classes\n",
        "        self._audio_max_len_samples = max_audio_len_s * self._fs  # TODO: Fix the audio synthesis code to always generate 60s of\n",
        "        # audio. Currently it generates audio till the last active sound event, which is not always 60s long. This is a\n",
        "        # quick fix to overcome that. We need this because, for processing and training we need the length of features\n",
        "        # to be fixed.\n",
        "\n",
        "        self._max_feat_frames = int(np.ceil(self._audio_max_len_samples / float(self._hop_len)))\n",
        "        self._max_label_frames = int(np.ceil(self._audio_max_len_samples / float(self._label_hop_len)))\n",
        "\n",
        "    @staticmethod\n",
        "    def _next_greater_power_of_2(x):\n",
        "        return 2 ** (x - 1).bit_length()\n",
        "\n",
        "    # -------------------------------  DCASE OUTPUT  FORMAT FUNCTIONS -------------------------------\n",
        "    \n",
        "\n",
        "    def write_output_format_file(self, _output_format_file, _output_format_dict):\n",
        "        \"\"\"\n",
        "        The function writes DCASE output format csv file, given output format dictionary\n",
        "        Parameters:\n",
        "        -----------------------\n",
        "        :param _output_format_file: file name to write\n",
        "        :param _output_format_dict: output dictionary\n",
        "        \"\"\"\n",
        "        _fid = open(_output_format_file, 'w')\n",
        "        for _frame_ind in _output_format_dict.keys():\n",
        "            for _value in _output_format_dict[_frame_ind]:\n",
        "                # Write Cartesian format output. Since baseline does not estimate track count we use a fixed value.\n",
        "                _fid.write('{},{},{},{},{},{}\\n'.format(int(_frame_ind), int(_value[0]), 0, float(_value[1]), float(_value[2]), float(_value[3])))\n",
        "        _fid.close()\n",
        "\n",
        "    def segment_labels(self, _pred_dict, _max_frames):\n",
        "        '''\n",
        "        The function Collects class-wise sound event location information in segments of length 1s from reference dataset\n",
        "        Paremeters:\n",
        "        -----------------\n",
        "        :param _pred_dict: Dictionary containing frame-wise sound event time and location information. Output of SELD method\n",
        "        :param _max_frames: Total number of frames in the recording\n",
        "        Return:\n",
        "        -----------------\n",
        "        :return: Dictionary containing class-wise sound event location information in each segment of audio\n",
        "                dictionary_name[segment-index][class-index] = list(frame-cnt-within-segment, azimuth, elevation)\n",
        "        '''\n",
        "        nb_blocks = int(np.ceil(_max_frames/float(self._nb_label_frames_1s)))\n",
        "        output_dict = {x: {} for x in range(nb_blocks)}\n",
        "        for frame_cnt in range(0, _max_frames, self._nb_label_frames_1s):\n",
        "\n",
        "            # Collect class-wise information for each block\n",
        "            # [class][frame] = <list of doa values>\n",
        "            # Data structure supports multi-instance occurence of same class\n",
        "            block_cnt = frame_cnt // self._nb_label_frames_1s\n",
        "            loc_dict = {}\n",
        "            for audio_frame in range(frame_cnt, frame_cnt+self._nb_label_frames_1s):\n",
        "                if audio_frame not in _pred_dict:\n",
        "                    continue\n",
        "                for value in _pred_dict[audio_frame]:\n",
        "                    if value[0] not in loc_dict:\n",
        "                        loc_dict[value[0]] = {}\n",
        "\n",
        "                    block_frame = audio_frame - frame_cnt\n",
        "                    if block_frame not in loc_dict[value[0]]:\n",
        "                        loc_dict[value[0]][block_frame] = []\n",
        "                    loc_dict[value[0]][block_frame].append(value[1:])\n",
        "\n",
        "            # Update the block wise details collected above in a global structure\n",
        "            for class_cnt in loc_dict:\n",
        "                if class_cnt not in output_dict[block_cnt]:\n",
        "                    output_dict[block_cnt][class_cnt] = []\n",
        "\n",
        "                keys = [k for k in loc_dict[class_cnt]]\n",
        "                values = [loc_dict[class_cnt][k] for k in loc_dict[class_cnt]]\n",
        "\n",
        "                output_dict[block_cnt][class_cnt].append([keys, values])\n",
        "\n",
        "        return output_dict\n",
        "\n",
        "    def regression_label_format_to_output_format(self, _sed_labels, _doa_labels):\n",
        "        \"\"\"\n",
        "        The function converts the sed (classification) and doa labels predicted in regression format to dcase output format.\n",
        "        Paremeters:\n",
        "        -----------------\n",
        "        :param _sed_labels: SED labels matrix [nb_frames, nb_classes]\n",
        "        :param _doa_labels: DOA labels matrix [nb_frames, 2*nb_classes] or [nb_frames, 3*nb_classes]\n",
        "        Return:\n",
        "        ------------------  \n",
        "        :return: _output_dict: returns a dict containing dcase output format\n",
        "        \"\"\"\n",
        "\n",
        "        _nb_classes = len(self._unique_classes)\n",
        "        _is_polar = _doa_labels.shape[-1] == 2*_nb_classes\n",
        "        _azi_labels, _ele_labels = None, None\n",
        "        _x, _y, _z = None, None, None\n",
        "        if _is_polar:\n",
        "            _azi_labels = _doa_labels[:, :_nb_classes]\n",
        "            _ele_labels = _doa_labels[:, _nb_classes:]\n",
        "        else:\n",
        "            _x = _doa_labels[:, :_nb_classes]\n",
        "            _y = _doa_labels[:, _nb_classes:2*_nb_classes]\n",
        "            _z = _doa_labels[:, 2*_nb_classes:]\n",
        "\n",
        "        _output_dict = {}\n",
        "        for _frame_ind in range(_sed_labels.shape[0]):\n",
        "            _tmp_ind = np.where(_sed_labels[_frame_ind, :])\n",
        "            if len(_tmp_ind[0]):\n",
        "                _output_dict[_frame_ind] = []\n",
        "                for _tmp_class in _tmp_ind[0]:\n",
        "                    if _is_polar:\n",
        "                        _output_dict[_frame_ind].append([_tmp_class, _azi_labels[_frame_ind, _tmp_class], _ele_labels[_frame_ind, _tmp_class]])\n",
        "                    else:\n",
        "                        _output_dict[_frame_ind].append([_tmp_class, _x[_frame_ind, _tmp_class], _y[_frame_ind, _tmp_class], _z[_frame_ind, _tmp_class]])\n",
        "        return _output_dict\n",
        "\n",
        "    # ------------------------------- Misc public functions -------------------------------\n",
        "    def get_classes(self):\n",
        "        \"\"\"\n",
        "        The function returns the unique classes dictionary\n",
        "        \"\"\"\n",
        "        return self._unique_classes\n",
        "\n",
        "    def get_normalized_feat_dir(self):\n",
        "        \"\"\"\n",
        "        The function returns the normalized feature folder path\n",
        "        \"\"\"\n",
        "        return os.path.join(\n",
        "            self._feat_label_dir,\n",
        "            '{}_norm'.format(self._dataset_combination)\n",
        "        )\n",
        "\n",
        "\n",
        "    def get_label_dir(self):\n",
        "        \"\"\"\n",
        "        The function returns the label feature folder path (if it is not the evaluation dataset)\n",
        "        \"\"\"\n",
        "        if self._is_eval:\n",
        "            return None\n",
        "        else:\n",
        "            return os.path.join(\n",
        "                self._feat_label_dir, '{}_label'.format(self._dataset_combination)\n",
        "            )\n",
        "\n",
        "    def get_nb_classes(self):\n",
        "        \"\"\"\n",
        "        The function returns the number of classes considered\n",
        "        \"\"\"\n",
        "        return len(self._unique_classes)\n",
        "\n",
        "    def nb_frames_1s(self):\n",
        "        \"\"\"\n",
        "        The function returns the number of frame contained in 1s\n",
        "        \"\"\"\n",
        "        return self._nb_label_frames_1s\n",
        "\n",
        "    def get_hop_len_sec(self):\n",
        "        \"\"\"\n",
        "        The function returns the hop lenght in seconds\n",
        "        \"\"\"\n",
        "        return self._hop_len_s\n",
        "\n",
        "    def get_nb_frames(self):\n",
        "        \"\"\"\n",
        "        The function returns the maximum number of frames considered\n",
        "        \"\"\"\n",
        "        return self._max_label_frames\n",
        "\n",
        "    def get_nb_mel_bins(self):\n",
        "        \"\"\"\n",
        "        The function returns the number of mel band considered\n",
        "        \"\"\"\n",
        "        return self._nb_mel_bins\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4kXXlRsPiAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#utils functions\n",
        "def collect_test_labels(_data_gen_test, _data_out, _nb_classes, quick_test):\n",
        "    \"\"\"\n",
        "        The function collects the ground truth of the testing dataset\n",
        "        Paremeters:\n",
        "        -----------------\n",
        "        :param _data_gen_test: data generator of test dataset \n",
        "        :param _data_out: data output label format\n",
        "        :param _nb_classes: number of classes considered\n",
        "        :param quick_test: flag to define is it is a quick test or not\n",
        "        Return\n",
        "        ------------------  \n",
        "        :return gt_sed: ground truth for sound event detection (SED), as integer \n",
        "        :return gt_doa: ground truth for directiona of arrival (doa)\n",
        "        \"\"\"\n",
        "\n",
        "    \n",
        "    # Collecting ground truth for test data\n",
        "    nb_batch = 2 if quick_test else _data_gen_test.get_total_batches_in_data()\n",
        "\n",
        "    batch_size = _data_out[0][0]\n",
        "    gt_sed = np.zeros((nb_batch * batch_size, _data_out[0][1], _data_out[0][2]))\n",
        "    gt_doa = np.zeros((nb_batch * batch_size, _data_out[0][1], _data_out[1][2]))\n",
        "\n",
        "    print(\"nb_batch in test: {}\".format(nb_batch))\n",
        "    cnt = 0\n",
        "    for tmp_feat, tmp_label in _data_gen_test.generate():\n",
        "        gt_sed[cnt * batch_size:(cnt + 1) * batch_size, :, :] = tmp_label[0]\n",
        "        if _data_gen_test.get_data_gen_mode():\n",
        "            doa_label = tmp_label[1]\n",
        "        else:\n",
        "          if doa_objective == 'masked_mse':\n",
        "            doa_label = tmp_label[1][:, :, _nb_classes:]\n",
        "          elif doa_objective == 'mse':\n",
        "            doa_label = tmp_label[1][:, :, :]\n",
        "        \n",
        "        gt_doa[cnt * batch_size:(cnt + 1) * batch_size, :, :] = doa_label\n",
        "        cnt = cnt + 1\n",
        "        if cnt == nb_batch:\n",
        "            break\n",
        "    return gt_sed.astype(int), gt_doa\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU4c8OjrguOU",
        "colab_type": "text"
      },
      "source": [
        "## Data generator\n",
        "\n",
        "The next cell implements the data generator. \n",
        "The data generator is a class, in order to properly set parameters related to training, validation and testing dataset. It also implements all the functions needed for the generator to correctly generate data to be given as input to the network. The generator works differently according to if the dataset is the development dataset or the evaluation dataset. In the first case, both feature and labels are returned while, in the second case, only the feature are returned, without the ground truth labels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGo2iqpxej5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#\n",
        "# Data generator for training the SELDnet\n",
        "#\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "class DataGenerator(object):\n",
        "    def __init__(\n",
        "            self, split=1, shuffle=True, per_file=False, is_eval=False\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        --------------\n",
        "        :param split: cross validation split to consider\n",
        "        :param shuffle: if the dataset will be shuffle or not\n",
        "        :param per_file: generating input features per file or not\n",
        "        :param is_eval: if the dataset is the evaluatin dataset or not \n",
        "        \"\"\"\n",
        "\n",
        "        self._per_file = per_file\n",
        "        self._is_eval = is_eval\n",
        "        self._splits = np.array(split)\n",
        "        self._batch_size = batch_size\n",
        "        self._feature_seq_len = feature_sequence_length\n",
        "        self._label_seq_len = label_sequence_length\n",
        "        self._shuffle = shuffle\n",
        "        self._feat_cls = FeatureClass(is_eval=self._is_eval)\n",
        "        self._label_dir = self._feat_cls.get_label_dir()\n",
        "        self._feat_dir = self._feat_cls.get_normalized_feat_dir()\n",
        "        self._data_aug = dataset_aug\n",
        "\n",
        "        self._filenames_list = list()\n",
        "        self._nb_frames_file = 0     # Using a fixed number of frames in feat files. Updated in _get_label_filenames_sizes()\n",
        "        self._nb_mel_bins = self._feat_cls.get_nb_mel_bins()\n",
        "        self._nb_ch = None\n",
        "        self._label_len = None  # total length of label - DOA + SED\n",
        "        self._doa_len = None    # DOA label length\n",
        "        self._class_dict = self._feat_cls.get_classes()\n",
        "        self._nb_classes = self._feat_cls.get_nb_classes()\n",
        "        self._get_filenames_list_and_feat_label_sizes()\n",
        "\n",
        "        self._feature_batch_seq_len = self._batch_size*self._feature_seq_len\n",
        "        self._label_batch_seq_len = self._batch_size*self._label_seq_len\n",
        "        self._circ_buf_feat = None\n",
        "        self._circ_buf_label = None\n",
        "\n",
        "        if self._per_file:\n",
        "            self._nb_total_batches = len(self._filenames_list)\n",
        "        else:\n",
        "            self._nb_total_batches = int(np.floor((len(self._filenames_list) * self._nb_frames_file /\n",
        "                                               float(self._feature_batch_seq_len))))\n",
        "\n",
        "\n",
        "        print(\n",
        "            '\\tDatagen_mode: {}, nb_files: {}, nb_classes:{}\\n'\n",
        "            '\\tnb_frames_file: {}, feat_len: {}, nb_ch: {}, label_len:{}\\n'.format(\n",
        "                'eval' if self._is_eval else 'dev', len(self._filenames_list),  self._nb_classes,\n",
        "                self._nb_frames_file, self._nb_mel_bins, self._nb_ch, self._label_len\n",
        "                )\n",
        "        )\n",
        "\n",
        "        print(\n",
        "            '\\tDataset: {}, split: {}\\n'\n",
        "            '\\tbatch_size: {}, feat_seq_len: {}, label_seq_len: {}, shuffle: {}\\n'\n",
        "            '\\tTotal batches in dataset: {}\\n'\n",
        "            '\\tlabel_dir: {}\\n '\n",
        "            '\\tfeat_dir: {}\\n'.format(\n",
        "                dataset, split,\n",
        "                self._batch_size, self._feature_seq_len, self._label_seq_len, self._shuffle,\n",
        "                self._nb_total_batches,\n",
        "                self._label_dir, self._feat_dir\n",
        "            )\n",
        "        )\n",
        "\n",
        "    def get_data_sizes(self):\n",
        "        \"\"\"\n",
        "        The function returns the input features shape and label shape \n",
        "        Returns\n",
        "        ------------------  \n",
        "        :return feat_shape: input feature shape\n",
        "        :return label_shape: label shape\n",
        "        \"\"\"\n",
        "\n",
        "        feat_shape = (self._batch_size, self._nb_ch, self._feature_seq_len, self._nb_mel_bins)\n",
        "        if self._is_eval:\n",
        "            label_shape = None\n",
        "        else:\n",
        "            label_shape = [\n",
        "                (self._batch_size, self._label_seq_len, self._nb_classes),\n",
        "                (self._batch_size, self._label_seq_len, self._nb_classes*3)\n",
        "            ]\n",
        "        return feat_shape, label_shape\n",
        "\n",
        "    def get_total_batches_in_data(self):\n",
        "        \"\"\"\n",
        "        The function returns the total batches in data \n",
        "        Returns\n",
        "        ------------------  \n",
        "        :return _nb_total_batches: totale batches in data\n",
        "        \"\"\"\n",
        "        return self._nb_total_batches\n",
        "\n",
        "    def _get_filenames_list_and_feat_label_sizes(self):\n",
        "        \"\"\"\n",
        "        The function creates the filename list and set the feature label size  \n",
        "        \"\"\"\n",
        "        for filename in os.listdir(self._feat_dir):\n",
        "            if self._is_eval:\n",
        "              self._filenames_list.append(filename)\n",
        "            else:\n",
        "              #appending name to the list only if the file is in the right split which is considered\n",
        "              if int(filename[4]) in self._splits:\n",
        "                self._filenames_list.append(filename)\n",
        "\n",
        "        temp_feat = np.load(os.path.join(self._feat_dir, self._filenames_list[0]))\n",
        "        self._nb_frames_file = temp_feat.shape[0]\n",
        "        self._nb_ch = temp_feat.shape[1] // self._nb_mel_bins\n",
        "\n",
        "        if not self._is_eval:\n",
        "            filename = self._filenames_list[0].split('-')[0] + '.npy'\n",
        "            temp_label = np.load(os.path.join(self._label_dir, filename))\n",
        "            self._label_len = temp_label.shape[-1]\n",
        "            self._doa_len = (self._label_len - self._nb_classes)//self._nb_classes\n",
        "\n",
        "        if self._per_file:\n",
        "            self._batch_size = int(np.ceil(temp_feat.shape[0]/float(self._feature_seq_len)))\n",
        "\n",
        "        return\n",
        "\n",
        "    def generate(self):\n",
        "        \"\"\"\n",
        "        Generates batches of samples\n",
        "        :return: \n",
        "        \"\"\"\n",
        "\n",
        "        while 1:\n",
        "            if self._shuffle:\n",
        "                random.shuffle(self._filenames_list)\n",
        "\n",
        "            # Ideally this should have been outside the while loop. But while generating the test data we want the data\n",
        "            # to be the same exactly for all epoch's hence we keep it here.\n",
        "            self._circ_buf_feat = deque()\n",
        "            self._circ_buf_label = deque()\n",
        "\n",
        "            file_cnt = 0\n",
        "            if self._is_eval:\n",
        "                for i in range(self._nb_total_batches):\n",
        "                    # load feat and label to circular buffer. Always maintain atleast one batch worth feat and label in the\n",
        "                    # circular buffer. If not keep refilling it.\n",
        "                    while len(self._circ_buf_feat) < self._feature_batch_seq_len:\n",
        "                        temp_feat = np.load(os.path.join(self._feat_dir, self._filenames_list[file_cnt]))\n",
        "\n",
        "                        for row_cnt, row in enumerate(temp_feat):\n",
        "                            self._circ_buf_feat.append(row)\n",
        "\n",
        "                        # If self._per_file is True, this returns the sequences belonging to a single audio recording\n",
        "                        if self._per_file:\n",
        "                            extra_frames = self._feature_batch_seq_len - temp_feat.shape[0]\n",
        "                            extra_feat = np.ones((extra_frames, temp_feat.shape[1])) * 1e-6\n",
        "\n",
        "                            for row_cnt, row in enumerate(extra_feat):\n",
        "                                self._circ_buf_feat.append(row)\n",
        "\n",
        "                        file_cnt = file_cnt + 1\n",
        "\n",
        "                    # Read one batch size from the circular buffer\n",
        "                    feat = np.zeros((self._feature_batch_seq_len, self._nb_mel_bins * self._nb_ch))\n",
        "                    for j in range(self._feature_batch_seq_len):\n",
        "                        feat[j, :] = self._circ_buf_feat.popleft()\n",
        "                    feat = np.reshape(feat, (self._feature_batch_seq_len, self._nb_mel_bins, self._nb_ch))\n",
        "\n",
        "                    # Split to sequences\n",
        "                    feat = self._split_in_seqs(feat, self._feature_seq_len)\n",
        "\n",
        "                    yield feat\n",
        "\n",
        "            else:\n",
        "                for i in range(self._nb_total_batches):\n",
        "\n",
        "                    # load feat and label to circular buffer. Always maintain atleast one batch worth feat and label in the\n",
        "                    # circular buffer. If not keep refilling it.\n",
        "                    while len(self._circ_buf_feat) < self._feature_batch_seq_len:\n",
        "                        temp_feat = np.load(os.path.join(self._feat_dir, self._filenames_list[file_cnt]))\n",
        "                        if int(self._filenames_list[file_cnt].split('-')[1].split('.')[0]) == 0:\n",
        "                          label_name = (self._filenames_list[file_cnt].split('-')[0]) + '.npy'\n",
        "                          temp_label = np.load(os.path.join(self._label_dir, label_name))\n",
        "                        else:\n",
        "                          #augmented data \n",
        "                          temp_label = np.load(os.path.join(self._label_dir, self._filenames_list[file_cnt]))\n",
        "\n",
        "                        for f_row in temp_feat:\n",
        "                            self._circ_buf_feat.append(f_row)\n",
        "                        for l_row in temp_label:\n",
        "                            self._circ_buf_label.append(l_row)\n",
        "\n",
        "                        # If self._per_file is True, this returns the sequences belonging to a single audio recording\n",
        "                        if self._per_file:\n",
        "                            feat_extra_frames = self._feature_batch_seq_len - temp_feat.shape[0]\n",
        "                            extra_feat = np.ones((feat_extra_frames, temp_feat.shape[1])) * 1e-6\n",
        "\n",
        "                            label_extra_frames = self._label_batch_seq_len - temp_label.shape[0]\n",
        "                            extra_labels = np.zeros((label_extra_frames, temp_label.shape[1]))\n",
        "\n",
        "                            for f_row in extra_feat:\n",
        "                                self._circ_buf_feat.append(f_row)\n",
        "                            for l_row in extra_labels:\n",
        "                                self._circ_buf_label.append(l_row)\n",
        "\n",
        "                        file_cnt = file_cnt + 1\n",
        "\n",
        "                    # Read one batch size from the circular buffer\n",
        "                    feat = np.zeros((self._feature_batch_seq_len, self._nb_mel_bins * self._nb_ch))\n",
        "                    label = np.zeros((self._label_batch_seq_len, self._label_len))\n",
        "                    for j in range(self._feature_batch_seq_len):\n",
        "                        feat[j, :] = self._circ_buf_feat.popleft()\n",
        "                    for j in range(self._label_batch_seq_len):\n",
        "                        label[j, :] = self._circ_buf_label.popleft()\n",
        "                    feat = np.reshape(feat, (self._feature_batch_seq_len, self._nb_mel_bins, self._nb_ch))\n",
        "\n",
        "                    # Split to sequences\n",
        "                    feat = self._split_in_seqs(feat, self._feature_seq_len)\n",
        "                    label = self._split_in_seqs(label, self._label_seq_len)\n",
        "\n",
        "                    if doa_objective == 'masked_mse':\n",
        "                      label = [\n",
        "                          label[:, :, :self._nb_classes],  # SED labels\n",
        "                          label                            #SED + DOA LABEL\n",
        "                          ]\n",
        "                    elif doa_objective == 'mse':\n",
        "                      label = [\n",
        "                          label[:, :, :self._nb_classes],  # SED labels\n",
        "                          label[:, :, self._nb_classes:]   # DOA labels\n",
        "                          ]\n",
        "                    \n",
        "                    yield feat, label\n",
        "\n",
        "    def _split_in_seqs(self, data, _seq_len):\n",
        "        \"\"\"\n",
        "        The function splits the data in sequence lenght \n",
        "        Parameters:\n",
        "        --------------\n",
        "        :param data: data to be splitted \n",
        "        :param _seq_len: sequence lenght \n",
        "        Return:\n",
        "        ---------------\n",
        "        :return data: data spllited in sequence \n",
        "        \"\"\"\n",
        "        if len(data.shape) == 1:\n",
        "            if data.shape[0] % _seq_len:\n",
        "                data = data[:-(data.shape[0] % _seq_len), :]\n",
        "            data = data.reshape((data.shape[0] // _seq_len, _seq_len, 1))\n",
        "        elif len(data.shape) == 2:\n",
        "            if data.shape[0] % _seq_len:\n",
        "                data = data[:-(data.shape[0] % _seq_len), :]\n",
        "            data = data.reshape((data.shape[0] // _seq_len, _seq_len, data.shape[1]))\n",
        "        elif len(data.shape) == 3:\n",
        "            if data.shape[0] % _seq_len:\n",
        "                data = data[:-(data.shape[0] % _seq_len), :, :]\n",
        "            data = data.reshape((data.shape[0] // _seq_len, _seq_len, data.shape[1], data.shape[2]))\n",
        "        else:\n",
        "            print('ERROR: Unknown data dimensions: {}'.format(data.shape))\n",
        "            exit()\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def split_multi_channels(data, num_channels):\n",
        "        tmp = None\n",
        "        in_shape = data.shape\n",
        "        if len(in_shape) == 3:\n",
        "            hop = in_shape[2] / num_channels\n",
        "            tmp = np.zeros((in_shape[0], num_channels, in_shape[1], hop))\n",
        "            for i in range(num_channels):\n",
        "                tmp[:, i, :, :] = data[:, :, i * hop:(i + 1) * hop]\n",
        "        elif len(in_shape) == 4 and num_channels == 1:\n",
        "            tmp = np.zeros((in_shape[0], 1, in_shape[1], in_shape[2], in_shape[3]))\n",
        "            tmp[:, 0, :, :, :] = data\n",
        "        else:\n",
        "            print('ERROR: The input should be a 3D matrix but it seems to have dimensions: {}'.format(in_shape))\n",
        "            exit()\n",
        "        return tmp\n",
        "\n",
        "    def get_default_elevation(self):\n",
        "        \"\"\"\n",
        "        The function returns the default elevation value\n",
        "        \"\"\"\n",
        "        return self._default_ele\n",
        "\n",
        "    def get_azi_ele_list(self):\n",
        "        \"\"\"\n",
        "        The function returns azimuth elevation list\n",
        "        \"\"\"\n",
        "        return self._feat_cls.get_azi_ele_list()\n",
        "\n",
        "    def get_nb_classes(self):\n",
        "        \"\"\"\n",
        "        The function returns the number of classes considered\n",
        "        \"\"\"\n",
        "        return self._nb_classes\n",
        "\n",
        "    def nb_frames_1s(self):\n",
        "        \"\"\"\n",
        "        The function returns the number of frames in a 1s file\n",
        "        \"\"\"\n",
        "        return self._feat_cls.nb_frames_1s()\n",
        "\n",
        "    def get_hop_len_sec(self):\n",
        "        \"\"\"\n",
        "        The function returns hop length in seconds\n",
        "        \"\"\"\n",
        "        return self._feat_cls.get_hop_len_sec()\n",
        "\n",
        "    def get_classes(self):\n",
        "        \"\"\"\n",
        "        The function returns classes dictionsry\n",
        "        \"\"\"\n",
        "        return self._feat_cls.get_classes()\n",
        "    \n",
        "    def get_filelist(self):\n",
        "        \"\"\"\n",
        "        The function returns the file name list\n",
        "        \"\"\"\n",
        "        return self._filenames_list\n",
        "\n",
        "    def get_frame_per_file(self):\n",
        "        \"\"\"\n",
        "        The function returns the label batch sequence lenght\n",
        "        \"\"\"\n",
        "        return self._label_batch_seq_len\n",
        "\n",
        "    def get_nb_frames(self):\n",
        "        \"\"\"\n",
        "        The function returns the number of frames\n",
        "        \"\"\"\n",
        "        return self._feat_cls.get_nb_frames()\n",
        "    \n",
        "    def get_data_gen_mode(self):\n",
        "        \"\"\"\n",
        "        The function returns the data generation mode\n",
        "        \"\"\"\n",
        "        return self._is_eval\n",
        "\n",
        "    def write_output_format_file(self, _out_file, _out_dict):\n",
        "        \"\"\"\n",
        "        The function call the write_output_format_file functin and returns the result\n",
        "        \"\"\"\n",
        "        return self._feat_cls.write_output_format_file(_out_file, _out_dict)\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPO0CMI6hAOh",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "The next cell defines the CRNN proposed in this sytem. \n",
        "The goal is to train the CRNN for sound event detection and localization taking as input features log mel spectogram of the audio file training dataset, together with acoustic intensity vector (in case of FOA format) or generilized cross-validation (in case of MIC format). \n",
        "The network used for this task is a CRNN network using Gated Recurrent Units (GRU) as recurrent layers. In particular, the network has 5 convolutional layers using rectangular filters of size 1x48. \n",
        "This is followed by two parallel branches of Fully Connected (FC) layers, one for Sound Event Detection (SED) and one for Direction-Of-Arrival (DOA) estimation, sharing weights along time dimension.  The first FC layer of both branches uses linear activation while the last FC layer ofeach  branch uses a different activation function according to the task. The last FC layer in the SED branch contains 14 nodes using sigmoid activation (one node for each sound event classes tobe detected),  while the last FC layer in the DOA branch consists of 42 nodes using tanh activation (each of the sound event classesis  represented  by  3  nodes  relative  to  the  sound  event  location  inx, y, and z).  We use binary cross-entropy as loss function for the SED branch and mean square error (MSE) loss for DOA estimation branch, keeping the two branches separated. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfIq6h9HhB0B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The SELDnet architecture with our modifications proposed for the DCASE Challenge Task 3\n",
        "\n",
        "from tensorflow.keras.layers import Bidirectional, Conv2D, MaxPooling2D, Input, Concatenate\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Reshape, Permute\n",
        "from tensorflow.keras.layers import GRU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import TimeDistributed\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras\n",
        "\n",
        "# the network is channel last format \n",
        "tensorflow.keras.backend.set_image_data_format('channels_last')\n",
        "\n",
        "\n",
        "def get_model(data_in, data_out, dropout_rate, dropout_rate_cnn, dropout_rate_rnn, nb_cnn2d_filt, f_pool_size, t_pool_size,\n",
        "              rnn_size, fnn_size, weights, doa_objective, sed_threshold):\n",
        "    \"\"\"\n",
        "    The function defines the model which will be used to train the network\n",
        "    Parameters\n",
        "    --------------\n",
        "    :param data_in: input data \n",
        "    :param data_out: output data\n",
        "    :param dropout_rate: dropout_rate for fully connected layers\n",
        "    :param dropout_rate_rnn: dropout_rate for recurrent layers \n",
        "    :param dropout_rate_cnn: dropour_rate for convolutional layers\n",
        "    :param nb_cnn2d_filt: number of convolutional filters\n",
        "    :param f_pool_size: frequency pooling size\n",
        "    :param t_pool_size: time pooling size \n",
        "    :param rnn_size: recurrent size \n",
        "    :param fnn_size: fully connected layers size\n",
        "    :param weights: weigths\n",
        "    :param doa_objective: doa loss function - masked_mse for baseline 2019 system, mse for our system \n",
        "    :param sed_threshold: sound event detection threshold\n",
        "    Return:\n",
        "    ----------\n",
        "    :return model: the neural network model \n",
        "    \"\"\"\n",
        "    spec_start = Input(shape=(data_in[-2], data_in[-1], data_in[-3]))\n",
        "\n",
        "    # CNN\n",
        "    spec_cnn = spec_start\n",
        "    for i, convCnt in enumerate(f_pool_size):\n",
        "        spec_cnn = Conv2D(filters=nb_cnn2d_filt, kernel_size=(1, 48), padding='same')(spec_cnn)\n",
        "        spec_cnn = BatchNormalization(trainable=True)(spec_cnn, training=True)\n",
        "        spec_cnn = Activation('relu')(spec_cnn)\n",
        "        spec_cnn = MaxPooling2D(pool_size=(t_pool_size[i], f_pool_size[i]))(spec_cnn)\n",
        "        spec_cnn = Dropout(dropout_rate_cnn)(spec_cnn)\n",
        "\n",
        "    # RNN\n",
        "    #todo: none output\n",
        "    spec_rnn = Reshape((data_out[0][-2], spec_cnn.shape[-2]*spec_cnn.shape[-1]))(spec_cnn)\n",
        "    for nb_rnn_filt in rnn_size:\n",
        "        spec_rnn = Bidirectional(\n",
        "            GRU(nb_rnn_filt, activation='tanh', dropout=dropout_rate_rnn, recurrent_dropout=dropout_rate_rnn,\n",
        "                return_sequences=True, reset_after=False),\n",
        "            merge_mode='mul'\n",
        "        )(spec_rnn, training=True)\n",
        "\n",
        "    # FC - DOA\n",
        "    doa = spec_rnn\n",
        "    for nb_fnn_filt in fnn_size:\n",
        "        doa = TimeDistributed(Dense(nb_fnn_filt))(doa)\n",
        "        doa = Dropout(dropout_rate)(doa)\n",
        "\n",
        "    doa = TimeDistributed(Dense(data_out[1][-1]))(doa)\n",
        "    doa = Activation('tanh', name='doa_out')(doa)\n",
        "\n",
        "    # FC - SED\n",
        "    sed = spec_rnn\n",
        "    for nb_fnn_filt in fnn_size:\n",
        "        sed = TimeDistributed(Dense(nb_fnn_filt))(sed)\n",
        "        sed = Dropout(dropout_rate)(sed)\n",
        "    sed = TimeDistributed(Dense(data_out[0][-1]))(sed)\n",
        "    sed = Activation('sigmoid', name='sed_out')(sed)\n",
        "\n",
        "    model = None\n",
        "    if doa_objective is 'mse':\n",
        "        model = Model(inputs=spec_start, outputs=[sed, doa])\n",
        "        model.compile(optimizer=Adam(), loss=['binary_crossentropy', 'mse'], loss_weights=weights)\n",
        "    elif doa_objective is 'masked_mse':\n",
        "        doa_concat = Concatenate(axis=-1, name='doa_concat')([sed, doa])\n",
        "        model = Model(inputs=spec_start, outputs=[sed, doa_concat])\n",
        "        model.compile(optimizer=Adam(), loss=['binary_crossentropy', masked_mse], loss_weights=weights)\n",
        "    else:\n",
        "        print('ERROR: Unknown doa_objective: {}'.format(doa_objective))\n",
        "        exit()\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "def masked_mse(y_gt, model_out):\n",
        "    # SED mask: Use only the predicted DOAs when gt SED > 0.5\n",
        "    sed_out = y_gt[:, :, :nb_classes] >= sed_threshold #TODO fix this hardcoded value of number of classes\n",
        "    sed_out = tensorflow.keras.backend.repeat_elements(sed_out, 3, -1)\n",
        "    sed_out = tensorflow.keras.backend.cast(sed_out, 'float32')\n",
        "\n",
        "    # Use the mask to computed mse now. Normalize with the mask weights #TODO fix this hardcoded value of number of classes\n",
        "    return tensorflow.keras.backend.sqrt(tensorflow.keras.backend.sum(tensorflow.keras.backend.square(y_gt[:, :, nb_classes:] - model_out[:, :, nb_classes:]) * sed_out))/tensorflow.keras.backend.sum(sed_out)\n",
        "\n",
        "\n",
        "def load_seld_model(model_file, doa_objective):\n",
        "    \"\"\"\n",
        "        The function returns proper model, according to the doa loss function \n",
        "        Parameters:\n",
        "        --------------\n",
        "        :param model_file: name of file containign the model\n",
        "        :param doa_objective: doa loss function, masked-mse for baseline 2019 system, mse for our implementation of the system \n",
        "        Return:\n",
        "        ---------------\n",
        "        :return the loaded model\n",
        "        \"\"\"\n",
        "    if doa_objective is 'mse':\n",
        "        return load_model(model_file)\n",
        "    elif doa_objective is 'masked_mse':\n",
        "        return load_model(model_file, custom_objects={'masked_mse': masked_mse})\n",
        "    else:\n",
        "        print('ERROR: Unknown doa objective: {}'.format(doa_objective))\n",
        "        exit()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzmM7AGmNv4F",
        "colab_type": "text"
      },
      "source": [
        "## Parameters definition for the algorithm \n",
        "\n",
        "Definition of parameters such as cross-validation splits. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgT4oLrFHJUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "0e7cb908-5a6b-4cad-c425-3a22ba4981de"
      },
      "source": [
        "#variables and parameters definition\n",
        "feat_cls = FeatureClass()\n",
        "train_splits, val_splits, test_splits = None, None, None\n",
        "\n",
        "if mode == 'dev':\n",
        "      test_splits = [1]\n",
        "      val_splits = [2]\n",
        "      train_splits = [[3, 4, 5, 6]]\n",
        "\n",
        "elif mode == 'eval':\n",
        "      test_splits = [[7, 8]]\n",
        "      val_splits = [[1]]\n",
        "      train_splits = [[2, 3, 4, 5, 6]]\n",
        "\n",
        "avg_scores_val = []\n",
        "avg_scores_test = []\n",
        "\n",
        "print(\"Test split {}\".format(test_splits))\n",
        "print(\"Val split {}\".format(val_splits))\n",
        "print(\"Train split {}\".format(train_splits))\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test split [[7, 8]]\n",
            "Val split [[1]]\n",
            "Train split [[2, 3, 4, 5, 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4z0CjGOd5o0",
        "colab_type": "text"
      },
      "source": [
        "## Training of the network \n",
        "\n",
        "In the next cell, the different functions to train the network are called. The different training and validation dataset will be created in order to train the network with the training datset and validate it with the validation dataset. The network is going to be trained for 50 epochs, unless the patience is reached before. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZqY34-DomTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reshape_3Dto2D(A):\n",
        "  \"\"\"\n",
        "  The function reshapes the data given as input from 3D shape to 2D shape. \n",
        "  Parameters:\n",
        "  -------------\n",
        "  :param A: input data\n",
        "  Return:\n",
        "  -------------\n",
        "  :return: input data reshape \n",
        "  \"\"\"\n",
        "  return A.reshape(A.shape[0] * A.shape[1], A.shape[2])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC4ByFWqQTbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import json\n",
        "\n",
        "\n",
        "#iterating among the test_splits\n",
        "for split_cnt, split in enumerate(test_splits):\n",
        "    \n",
        "    print('\\n\\n')\n",
        "    print('-' * 85)\n",
        "    print('-' * 39 + ' SPLIT {}'.format(str(split)) + '-' * 38)\n",
        "    print('-' * 85)\n",
        "    print(\"Quick test: \", quick_test)\n",
        "\n",
        "    ########################### Creation of all necessary folders ####################################\n",
        "\n",
        "    #creation split folder inside the output folder \n",
        "    split_folder = os.path.join(output_dir, 'split_{}'.format(split_cnt))\n",
        "    create_folder(split_folder)\n",
        "\n",
        "    #creation prediction folder inside the split folder (predictions will be saved here)\n",
        "    prediction_folder = os.path.join(split_folder, \"\".join(['prediction_', dataset, '/']))\n",
        "    create_folder(prediction_folder)\n",
        "\n",
        "    #creation history folder inside the split folder (history regarding validation loss and training loss will be saved here)\n",
        "    history_folder = os.path.join(split_folder, 'history/')\n",
        "    create_folder(history_folder)\n",
        "\n",
        "    #creation checkpoint folder inside the split folder (checkpoints will be saved here)\n",
        "    checkpoint_folder = os.path.join(split_folder, 'checkpoints/')\n",
        "    create_folder(checkpoint_folder)\n",
        "    checkpoint_path = checkpoint_folder + 'cp.ckpt'\n",
        "    checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "    #creation model folder inside the split folder (models will be saved here)\n",
        "    model_dir = os.path.join(split_folder, 'models/')\n",
        "    create_folder(model_dir)\n",
        "\n",
        "    #creation of datafile path were to save all the metadata we will need to retrieve information in case of sudden interruptions due to\n",
        "    #network connection, running out of memory, etc. \n",
        "    datafilepath = split_folder + '/data.json'\n",
        "    \n",
        "    ###################################  Training fo the network ##########################################################\n",
        "\n",
        "    # Load trainining data\n",
        "    print('Loading training dataset:')\n",
        "    data_gen_train = DataGenerator(\n",
        "        split=train_splits[split_cnt]\n",
        "    )\n",
        "\n",
        "    # Load validation data\n",
        "    print('Loading validation dataset:')\n",
        "    data_gen_val = DataGenerator(\n",
        "        split=val_splits[split_cnt], shuffle=False\n",
        "    )\n",
        "\n",
        "    # Collect the reference labels for validation data and properly reshape them \n",
        "    data_in, data_out = data_gen_train.get_data_sizes()\n",
        "    print('FEATURES:\\n\\tdata_in: {}\\n\\tdata_out: {}\\n'.format(data_in, data_out))\n",
        "    nb_classes = data_gen_train.get_nb_classes()\n",
        "    gt = collect_test_labels(data_gen_val, data_out, nb_classes, quick_test)\n",
        "    sed_gt = reshape_3Dto2D(gt[0])\n",
        "    doa_gt = reshape_3Dto2D(gt[1])\n",
        "\n",
        "    print('MODEL:\\n\\tdropout_rate: {}\\n\\tCNN: nb_cnn_filt: {}, f_pool_size{}, t_pool_size{}\\n\\trnn_size: {}, fnn_size: {}\\n\\tdoa_objective: {}\\n'.format(\n",
        "        dropout_rate, nb_cnn2d_filt, f_pool_size, t_pool_size, rnn_size, \n",
        "        fnn_size, doa_objective))\n",
        "\n",
        "    print('Using loss weights : {}'.format(loss_weights))\n",
        "\n",
        "    # calling the model and start the training\n",
        "    model = get_model(data_in=data_in, data_out=data_out, dropout_rate=dropout_rate, dropout_rate_cnn=dropout_rate_cnn, dropout_rate_rnn=dropout_rate_rnn,\n",
        "                                      nb_cnn2d_filt=nb_cnn2d_filt, f_pool_size=f_pool_size, t_pool_size=t_pool_size, \n",
        "                                      rnn_size=rnn_size, fnn_size=fnn_size, \n",
        "                                      weights=loss_weights, doa_objective=doa_objective, sed_threshold=sed_threshold)\n",
        "\n",
        " \n",
        "    \n",
        "    #checkpoint_callback\n",
        "    cp_callback = tensorflow.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 save_freq = data_gen_train.get_total_batches_in_data() * epochs_per_fit,\n",
        "                                                 verbose=1)\n",
        " \n",
        "    nb_epoch = 2 if quick_test else nb_epochs\n",
        "    \n",
        "    data = {}\n",
        "    epoch_cnt = -1 \n",
        "    patience_cnt = 0\n",
        "\n",
        "    # start training\n",
        "    for _ in range(nb_epoch):  \n",
        "\n",
        "      start = time.time() \n",
        "\n",
        "      #so we can start from zero\n",
        "      epoch_cnt += 1\n",
        "      data['epoch'] = epoch_cnt\n",
        "      print(\"epoch: {}\".format(epoch_cnt))\n",
        "\n",
        "      #check if the checkpoit folder is empty or not. If not empty, the training probably stoppe for sudden interruptions\n",
        "      #Loading the model's weights and information related to the epoch will be possible to start training the network again for the same epoch\n",
        "      #with the same value\n",
        "      if len(os.listdir(checkpoint_folder)) != 0 and epoch_cnt == 0:\n",
        "\n",
        "       # laoding network's weight \n",
        "        print(\"Checkpoints exist: Loading weight\")\n",
        "        model.load_weights(tensorflow.train.latest_checkpoint(checkpoint_folder))\n",
        "        #loading information relateds to the system and epoch of interruction\n",
        "        with open(datafilepath, \"r\") as fp:\n",
        "          data = json.load(fp)  \n",
        "        epoch_cnt = data['epoch']\n",
        "        patience_cnt = data['patience_cnt']\n",
        "        val_loss_prec = data['val_loss_prec']\n",
        "        print(\"Restoring from epoch: {}\".format(data['epoch']))\n",
        "\n",
        "      #saving the current epoch\n",
        "      with open(datafilepath, \"w+\") as fp:\n",
        "        json.dump(data, fp)\n",
        "\n",
        "      #check if patience has been reached \n",
        "      if epoch_cnt >= nb_epoch or patience_cnt >= patience:\n",
        "        print(\"Training finished\")\n",
        "        break   \n",
        "\n",
        "      # fitting the model\n",
        "      hist = model.fit(\n",
        "                    x=data_gen_train.generate(),\n",
        "                    steps_per_epoch=2 if quick_test else data_gen_train.get_total_batches_in_data(),\n",
        "                    epochs=epochs_per_fit,\n",
        "                    callbacks=[cp_callback], \n",
        "                    validation_data = data_gen_val.generate(),\n",
        "                    validation_steps = 2 if quick_test else data_gen_val.get_total_batches_in_data(),\n",
        "      )\n",
        "      \n",
        "\n",
        "      # predict once per epoch\n",
        "      pred = model.predict(\n",
        "              x=data_gen_val.generate(),\n",
        "              steps=2 if quick_test else data_gen_val.get_total_batches_in_data(),\n",
        "              verbose=2,\n",
        "        )\n",
        "\n",
        "      ################################ Savign the model and predictions ################################################################\n",
        "\n",
        "      #saving the model\n",
        "      model_name = '{}_model.h5'.format(epoch_cnt)\n",
        "      model_path = model_dir + model_name\n",
        "      model.save(model_path)\n",
        "\n",
        "      pred_sed_filename = 'pred_%s_sed_%s' % (dataset, str(epoch_cnt))\n",
        "      pred_doa_filename = 'pred_%s_doa_%s' % (dataset, str(epoch_cnt))\n",
        "      \n",
        "      # saving history (training loss and validation loss information)\n",
        "      hist_loss_filename = os.path.join(\"\".join([history_folder, 'pred_%s_%s_hist_loss.json' % (dataset, str(epoch_cnt))]))\n",
        "      with open(hist_loss_filename, \"w+\") as fp:\n",
        "        json.dump(str(hist.history), fp)\n",
        "        \n",
        "      # saving sound event detection prediction\n",
        "      np.save(os.path.join(prediction_folder + pred_sed_filename), pred[0])\n",
        "      #print(\"File prediction sed saved {}\".format(os.path.join(prediction_folder + pred_sed_filename)))\n",
        "\n",
        "      # saving direction of arrival prediction\n",
        "      np.save(os.path.join(prediction_folder + pred_doa_filename), pred[1])\n",
        "      #print(\"File prediction doa saved {}\".format(os.path.join(prediction_folder + pred_doa_filename)))\n",
        "\n",
        "      #if validation loss is not increasing, the patience count will increase \n",
        "      if epoch_cnt > 0 and hist.history['val_loss'][-1] >= val_loss_prec:\n",
        "        patience_cnt += 1\n",
        "      else:\n",
        "        patience_cnt = 0\n",
        "        \n",
        "      val_loss_prec = hist.history['val_loss'][-1]\n",
        "      data['patience_cnt'] = patience_cnt\n",
        "      data['val_loss_prec'] = val_loss_prec\n",
        "\n",
        "      # if patience is reached, the trainign stops\n",
        "      if patience_cnt >= patience:\n",
        "        print(\"Ealy stop breaking\")\n",
        "        data['nb_epochs'] = epoch_cnt\n",
        "        break\n",
        "\n",
        "      with open(datafilepath, \"w+\") as fp:\n",
        "        json.dump(data, fp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFOuQXWjkJsv",
        "colab_type": "text"
      },
      "source": [
        "## Evaluation part\n",
        "The network predictions are evaluated considering the joint nature  of  localization-and-detection, as proposed in [2]. In particular, ER and F are related to the SED task and they are location-dependent. A prediction is considered true positive only if under a distance threshold of 20◦from the reference.  LE_CD (localization error) and LR_CD (localization recall), are related to DOA estimation, being classification-dependent. Instead of considering all outputs, they are computed across each class only. All metrics are computed in  one-second non-overlapping frames. More information about the evaluation metrics can be found at [2].  \n",
        "\n",
        "[2]: Mesaros, Annamaria, et al. \"Joint measurement of localization and detection of sound events.\" 2019 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA). IEEE, 2019."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0pY2EupnJ-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Implements the core metrics from sound event detection evaluation module http://tut-arg.github.io/sed_eval/ and\n",
        "\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "eps = np.finfo(np.float).eps\n",
        "\n",
        "\n",
        "##########################################################################################\n",
        "# SELD scoring functions - class implementation\n",
        "#\n",
        "# NOTE: Supports only one-hot labels for both SED and DOA. Doesnt work for baseline method\n",
        "# directly, since it estimated DOA in regression approach. Check below the class for\n",
        "# one shot (function) implementations of all metrics. The function implementation has\n",
        "# support for both one-hot labels and regression values of DOA estimation.\n",
        "##########################################################################################\n",
        "\n",
        "###############################################################\n",
        "# SED scoring functions\n",
        "###############################################################\n",
        "class evaluationmetric_SELDMetrics(object):\n",
        "  def __init__(self, nb_frames_1s=None, data_gen=None):\n",
        "        # SED params\n",
        "        self._S = 0\n",
        "        self._D = 0\n",
        "        self._I = 0\n",
        "        self._TP = 0\n",
        "        self._Nref = 0\n",
        "        self._Nsys = 0\n",
        "        self._block_size = nb_frames_1s\n",
        "\n",
        "        # DOA params\n",
        "        self._doa_loss_pred_cnt = 0\n",
        "        self._nb_frames = 0\n",
        "\n",
        "        self._doa_loss_pred = 0\n",
        "        self._nb_good_pks = 0\n",
        "\n",
        "        self._data_gen = data_gen\n",
        "\n",
        "        self._less_est_cnt, self._less_est_frame_cnt = 0, 0\n",
        "        self._more_est_cnt, self._more_est_frame_cnt = 0, 0\n",
        "\n",
        "  def f1_overall_framewise(O, T):\n",
        "    TP = ((2 * T - O) == 1).sum()\n",
        "    Nref, Nsys = T.sum(), O.sum()\n",
        "    self._TP += TP\n",
        "    self._Nref += Nref\n",
        "    self._Nsys += Nsys\n",
        "\n",
        "\n",
        "  def er_overall_framewise(O, T):\n",
        "      FP = np.logical_and(T == 0, O == 1).sum(1)\n",
        "      FN = np.logical_and(T == 1, O == 0).sum(1)\n",
        "      S = np.minimum(FP, FN).sum()\n",
        "      D = np.maximum(0, FN - FP).sum()\n",
        "      I = np.maximum(0, FP - FN).sum()\n",
        "      self._S += S\n",
        "      self._D += D\n",
        "      self._I += I\n",
        "\n",
        "\n",
        "  def f1_overall_1sec(O, T, block_size):\n",
        "    new_size = int(np.ceil(float(O.shape[0]) / self._block_size))\n",
        "    O_block = np.zeros((new_size, O.shape[1]))\n",
        "    T_block = np.zeros((new_size, O.shape[1]))\n",
        "    for i in range(0, new_size):\n",
        "      O_block[i, :] = np.max(O[int(i * self._block_size):int(i * self._block_size + self._block_size - 1), :], axis=0)\n",
        "      T_block[i, :] = np.max(T[int(i * self._block_size):int(i * self._block_size + self._block_size - 1), :], axis=0)\n",
        "    return self.f1_overall_framewise(O_block, T_block)\n",
        "\n",
        "  def er_overall_1sec(self, O, T):\n",
        "    new_size = int(np.ceil(float(O.shape[0]) / self._block_size))\n",
        "    O_block = np.zeros((new_size, O.shape[1]))\n",
        "    T_block = np.zeros((new_size, O.shape[1]))\n",
        "    for i in range(0, new_size):\n",
        "      O_block[i, :] = np.max(O[int(i * self._block_size):int(i * self._block_size + self._block_size - 1), :], axis=0)\n",
        "      T_block[i, :] = np.max(T[int(i * self._block_size):int(i * self._block_size + self._block_size - 1), :], axis=0)\n",
        "    return self.er_overall_framewise(O_block, T_block)\n",
        "\n",
        "  def update_sed_scores(self, pred, gt):\n",
        "    self.f1_overall_1sec(pred, gt)\n",
        "    self.er_overall_1sec(pred, gt)\n",
        "\n",
        "\n",
        "  def compute_sed_scores(self):\n",
        "\n",
        "      ER = (self._S + self._D + self._I) / (self._Nref + 0.0)\n",
        "\n",
        "      prec = float(self._TP) / float(self._Nsys + eps)\n",
        "      recall = float(self._TP) / float(self._Nref + eps)\n",
        "      F = 2 * prec * recall / (prec + recall + eps)\n",
        "\n",
        "      return ER, F\n",
        "\n",
        "  def update_doa_scores(self, pred_doa_thresholded, gt_doa):\n",
        "      self._doa_loss_pred_cnt += np.sum(pred_doa_thresholded)\n",
        "      self._nb_frames += pred_doa_thresholded.shape[0]\n",
        "\n",
        "      for frame in range(pred_doa_thresholded.shape[0]):\n",
        "        nb_gt_peaks = int(np.sum(gt_doa[frame, :]))\n",
        "        nb_pred_peaks = int(np.sum(pred_doa_thresholded[frame, :]))\n",
        "\n",
        "            # good_frame_cnt includes frames where the nb active sources were zero in both groundtruth and prediction\n",
        "        if nb_gt_peaks == nb_pred_peaks:\n",
        "          self._nb_good_pks += 1\n",
        "        elif nb_gt_peaks > nb_pred_peaks:\n",
        "          self._less_est_frame_cnt += 1\n",
        "          self._less_est_cnt += (nb_gt_peaks - nb_pred_peaks)\n",
        "        elif nb_pred_peaks > nb_gt_peaks:\n",
        "          self._more_est_frame_cnt += 1\n",
        "          self._more_est_cnt += (nb_pred_peaks - nb_gt_peaks)\n",
        "\n",
        "            # when nb_ref_doa > nb_estimated_doa, ignores the extra ref doas and scores only the nearest matching doas\n",
        "            # similarly, when nb_estimated_doa > nb_ref_doa, ignores the extra estimated doa and scores the remaining matching doas\n",
        "        if nb_gt_peaks and nb_pred_peaks:\n",
        "          pred_ind = np.where(pred_doa_thresholded[frame] == 1)[1]\n",
        "          pred_list_rad = np.array(self._data_gen .get_matrix_index(pred_ind)) * np.pi / 180\n",
        "\n",
        "          gt_ind = np.where(gt_doa[frame] == 1)[1]\n",
        "          gt_list_rad = np.array(self._data_gen .get_matrix_index(gt_ind)) * np.pi / 180\n",
        "\n",
        "          frame_dist = distance_between_gt_pred(gt_list_rad.T, pred_list_rad.T)\n",
        "          self._doa_loss_pred += frame_dist \n",
        "\n",
        "  def compute_doa_scores(self):\n",
        "        doa_error = self._doa_loss_pred / self._doa_loss_pred_cnt\n",
        "        frame_recall = self._nb_good_pks / float(self._nb_frames)\n",
        "        return doa_error, frame_recall\n",
        "\n",
        "  def reset(self):\n",
        "        # SED params\n",
        "        self._S = 0\n",
        "        self._D = 0\n",
        "        self._I = 0\n",
        "        self._TP = 0\n",
        "        self._Nref = 0\n",
        "        self._Nsys = 0\n",
        "\n",
        "        # DOA params\n",
        "        self._doa_loss_pred_cnt = 0\n",
        "        self._nb_frames = 0\n",
        "\n",
        "        self._doa_loss_pred = 0\n",
        "        self._nb_good_pks = 0\n",
        "\n",
        "        self._less_est_cnt, self._less_est_frame_cnt = 0, 0\n",
        "        self._more_est_cnt, self._more_est_frame_cnt = 0, 0\n",
        "\n",
        "\n",
        "###############################################################\n",
        "# DOA scoring functions\n",
        "###############################################################\n",
        "\n",
        "\n",
        "def f1_overall_framewise(O, T):\n",
        "  if len(O.shape) == 3:\n",
        "      O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
        "  TP = ((2 * T - O) == 1).sum()\n",
        "  Nref, Nsys = T.sum(), O.sum()\n",
        "\n",
        "  prec = float(TP) / float(Nsys + eps)\n",
        "  recall = float(TP) / float(Nref + eps)\n",
        "  f1_score = 2 * prec * recall / (prec + recall + eps)\n",
        "  return f1_score\n",
        "\n",
        "\n",
        "def er_overall_framewise(O, T):\n",
        "  if len(O.shape) == 3:\n",
        "    O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
        "\n",
        "  FP = np.logical_and(T == 0, O == 1).sum(1)\n",
        "  FN = np.logical_and(T == 1, O == 0).sum(1)\n",
        "\n",
        "  S = np.minimum(FP, FN).sum()\n",
        "  D = np.maximum(0, FN-FP).sum()\n",
        "  I = np.maximum(0, FP-FN).sum()\n",
        "\n",
        "  Nref = T.sum()\n",
        "  ER = (S+D+I) / (Nref + 0.0)\n",
        "  return ER\n",
        "\n",
        "\n",
        "def f1_overall_1sec(O, T, block_size):\n",
        "  if len(O.shape) == 3:\n",
        "      O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
        "  new_size = int(np.ceil(float(O.shape[0]) / block_size))\n",
        "  O_block = np.zeros((new_size, O.shape[1]))\n",
        "  T_block = np.zeros((new_size, O.shape[1]))\n",
        "  for i in range(0, new_size):\n",
        "    O_block[i, :] = np.max(O[int(i * block_size):int(i * block_size + block_size - 1), :], axis=0)\n",
        "    T_block[i, :] = np.max(T[int(i * block_size):int(i * block_size + block_size - 1), :], axis=0)\n",
        "  return f1_overall_framewise(O_block, T_block)\n",
        "\n",
        "\n",
        "def er_overall_1sec(O, T, block_size):\n",
        "  if len(O.shape) == 3:\n",
        "      O, T = reshape_3Dto2D(O), reshape_3Dto2D(T)\n",
        "  new_size = int(np.ceil(float(O.shape[0]) / block_size))\n",
        "  O_block = np.zeros((new_size, O.shape[1]))\n",
        "  T_block = np.zeros((new_size, O.shape[1]))\n",
        "  for i in range(0, new_size):\n",
        "    O_block[i, :] = np.max(O[int(i * block_size):int(i * block_size + block_size - 1), :], axis=0)\n",
        "    T_block[i, :] = np.max(T[int(i * block_size):int(i * block_size + block_size - 1), :], axis=0)\n",
        "  return er_overall_framewise(O_block, T_block)\n",
        "\n",
        "\n",
        "def compute_sed_scores(pred, gt, nb_frames_1s):\n",
        "  f1o = f1_overall_1sec(pred, gt, nb_frames_1s)\n",
        "  ero = er_overall_1sec(pred, gt, nb_frames_1s)\n",
        "  scores = [ero, f1o]\n",
        "  return scores\n",
        "\n",
        "\n",
        "###############################################################\n",
        "# DOA scoring functions\n",
        "###############################################################\n",
        "\n",
        "\n",
        "def compute_doa_scores_regr_xyz(pred_doa, gt_doa, pred_sed, gt_sed):\n",
        "    \"\"\"\n",
        "        Compute DOA metrics when DOA is estimated using regression approach\n",
        "\n",
        "    :param pred_doa: predicted doa_labels is of dimension [nb_frames, 3*nb_classes],\n",
        "                        nb_classes each for x, y, and z axes,\n",
        "                        if active, the DOA values will be in real numbers [-1 1] range, else, it will contain default doa values of (0, 0, 0)\n",
        "    :param gt_doa: reference doa_labels is of dimension [nb_frames, 3*nb_classes],\n",
        "    :param pred_sed: predicted sed label of dimension [nb_frames, nb_classes] which is 1 for active sound event else zero\n",
        "    :param gt_sed: reference sed label of dimension [nb_frames, nb_classes] which is 1 for active sound event else zero\n",
        "    :return:\n",
        "    \"\"\"\n",
        "\n",
        "    nb_src_gt_list = np.zeros(gt_doa.shape[0]).astype(int)\n",
        "    nb_src_pred_list = np.zeros(gt_doa.shape[0]).astype(int)\n",
        "    good_frame_cnt = 0\n",
        "    doa_loss_pred = 0.0\n",
        "    nb_sed = gt_sed.shape[-1]\n",
        "\n",
        "    less_est_cnt, less_est_frame_cnt = 0, 0\n",
        "    more_est_cnt, more_est_frame_cnt = 0, 0\n",
        "\n",
        "    for frame_cnt, sed_frame in enumerate(gt_sed):\n",
        "        nb_src_gt_list[frame_cnt] = int(np.sum(sed_frame))\n",
        "        nb_src_pred_list[frame_cnt] = int(np.sum(pred_sed[frame_cnt]))\n",
        "\n",
        "        # good_frame_cnt includes frames where the nb active sources were zero in both groundtruth and prediction\n",
        "        if nb_src_gt_list[frame_cnt] == nb_src_pred_list[frame_cnt]:\n",
        "            good_frame_cnt = good_frame_cnt + 1\n",
        "        elif nb_src_gt_list[frame_cnt] > nb_src_pred_list[frame_cnt]:\n",
        "            less_est_cnt = less_est_cnt + nb_src_gt_list[frame_cnt] - nb_src_pred_list[frame_cnt]\n",
        "            less_est_frame_cnt = less_est_frame_cnt + 1\n",
        "        elif nb_src_gt_list[frame_cnt] < nb_src_pred_list[frame_cnt]:\n",
        "            more_est_cnt = more_est_cnt + nb_src_pred_list[frame_cnt] - nb_src_gt_list[frame_cnt]\n",
        "            more_est_frame_cnt = more_est_frame_cnt + 1\n",
        "\n",
        "        # when nb_ref_doa > nb_estimated_doa, ignores the extra ref doas and scores only the nearest matching doas\n",
        "        # similarly, when nb_estimated_doa > nb_ref_doa, ignores the extra estimated doa and scores the remaining matching doas\n",
        "        if nb_src_gt_list[frame_cnt] and nb_src_pred_list[frame_cnt]:\n",
        "            # DOA Loss with respect to predicted confidence\n",
        "            sed_frame_gt = gt_sed[frame_cnt]\n",
        "            doa_frame_gt_x = gt_doa[frame_cnt][:nb_sed][sed_frame_gt == 1]\n",
        "            doa_frame_gt_y = gt_doa[frame_cnt][nb_sed:2*nb_sed][sed_frame_gt == 1]\n",
        "            doa_frame_gt_z = gt_doa[frame_cnt][2*nb_sed:][sed_frame_gt == 1]\n",
        "\n",
        "            sed_frame_pred = pred_sed[frame_cnt]\n",
        "            doa_frame_pred_x = pred_doa[frame_cnt][:nb_sed][sed_frame_pred == 1]\n",
        "            doa_frame_pred_y = pred_doa[frame_cnt][nb_sed:2*nb_sed][sed_frame_pred == 1]\n",
        "            doa_frame_pred_z = pred_doa[frame_cnt][2*nb_sed:][sed_frame_pred == 1]\n",
        "\n",
        "            doa_loss_pred += distance_between_gt_pred_xyz(np.vstack((doa_frame_gt_x, doa_frame_gt_y, doa_frame_gt_z)).T,\n",
        "                                                      np.vstack((doa_frame_pred_x, doa_frame_pred_y, doa_frame_pred_z)).T)\n",
        "\n",
        "    doa_loss_pred_cnt = np.sum(nb_src_pred_list)\n",
        "    if doa_loss_pred_cnt:\n",
        "        doa_loss_pred /= doa_loss_pred_cnt\n",
        "\n",
        "    frame_recall = good_frame_cnt / float(gt_sed.shape[0])\n",
        "    er_metric = [doa_loss_pred, frame_recall, doa_loss_pred_cnt, good_frame_cnt, more_est_cnt, less_est_cnt]\n",
        "    return er_metric\n",
        "\n",
        "\n",
        "def compute_doa_scores_regr(pred_doa_rad, gt_doa_rad, pred_sed, gt_sed):\n",
        "    \"\"\"\n",
        "    The function computes DOA metrics when DOA is estimated using regression approach\n",
        "    Parameters:\n",
        "    -------------- \n",
        "    :param pred_doa_rad: predicted doa_labels is of dimension [nb_frames, 2*nb_classes],\n",
        "                        nb_classes each for azimuth and elevation angles,\n",
        "                        if active, the DOA values will be in RADIANS, else, it will contain default doa values\n",
        "    :param gt_doa_rad: reference doa_labels is of dimension [nb_frames, 2*nb_classes],\n",
        "                    nb_classes each for azimuth and elevation angles,\n",
        "                    if active, the DOA values will be in RADIANS, else, it will contain default doa values\n",
        "    :param pred_sed: predicted sed label of dimension [nb_frames, nb_classes] which is 1 for active sound event else zero\n",
        "    :param gt_sed: reference sed label of dimension [nb_frames, nb_classes] which is 1 for active sound event else zero\n",
        "    Return:\n",
        "    ------------\n",
        "    :return er_metric: error metrics related to DOA\n",
        "    \"\"\"\n",
        "\n",
        "    nb_src_gt_list = np.zeros(gt_doa_rad.shape[0]).astype(int)\n",
        "    nb_src_pred_list = np.zeros(gt_doa_rad.shape[0]).astype(int)\n",
        "    good_frame_cnt = 0\n",
        "    doa_loss_pred = 0.0\n",
        "    nb_sed = gt_sed.shape[-1]\n",
        "\n",
        "    less_est_cnt, less_est_frame_cnt = 0, 0\n",
        "    more_est_cnt, more_est_frame_cnt = 0, 0\n",
        "\n",
        "    for frame_cnt, sed_frame in enumerate(gt_sed):\n",
        "        nb_src_gt_list[frame_cnt] = int(np.sum(sed_frame))\n",
        "        nb_src_pred_list[frame_cnt] = int(np.sum(pred_sed[frame_cnt]))\n",
        "\n",
        "        # good_frame_cnt includes frames where the nb active sources were zero in both groundtruth and prediction\n",
        "        if nb_src_gt_list[frame_cnt] == nb_src_pred_list[frame_cnt]:\n",
        "            good_frame_cnt = good_frame_cnt + 1\n",
        "        elif nb_src_gt_list[frame_cnt] > nb_src_pred_list[frame_cnt]:\n",
        "            less_est_cnt = less_est_cnt + nb_src_gt_list[frame_cnt] - nb_src_pred_list[frame_cnt]\n",
        "            less_est_frame_cnt = less_est_frame_cnt + 1\n",
        "        elif nb_src_gt_list[frame_cnt] < nb_src_pred_list[frame_cnt]:\n",
        "            more_est_cnt = more_est_cnt + nb_src_pred_list[frame_cnt] - nb_src_gt_list[frame_cnt]\n",
        "            more_est_frame_cnt = more_est_frame_cnt + 1\n",
        "\n",
        "        # when nb_ref_doa > nb_estimated_doa, ignores the extra ref doas and scores only the nearest matching doas\n",
        "        # similarly, when nb_estimated_doa > nb_ref_doa, ignores the extra estimated doa and scores the remaining matching doas\n",
        "        if nb_src_gt_list[frame_cnt] and nb_src_pred_list[frame_cnt]:\n",
        "            # DOA Loss with respect to predicted confidence\n",
        "            sed_frame_gt = gt_sed[frame_cnt]\n",
        "            doa_frame_gt_azi = gt_doa_rad[frame_cnt][:nb_sed][sed_frame_gt == 1]\n",
        "            doa_frame_gt_ele = gt_doa_rad[frame_cnt][nb_sed:][sed_frame_gt == 1]\n",
        "\n",
        "            sed_frame_pred = pred_sed[frame_cnt]\n",
        "            doa_frame_pred_azi = pred_doa_rad[frame_cnt][:nb_sed][sed_frame_pred == 1]\n",
        "            doa_frame_pred_ele = pred_doa_rad[frame_cnt][nb_sed:][sed_frame_pred == 1]\n",
        "\n",
        "            doa_loss_pred += distance_between_gt_pred(np.vstack((doa_frame_gt_azi, doa_frame_gt_ele)).T,\n",
        "                                                      np.vstack((doa_frame_pred_azi, doa_frame_pred_ele)).T)\n",
        "\n",
        "    doa_loss_pred_cnt = np.sum(nb_src_pred_list)\n",
        "    if doa_loss_pred_cnt:\n",
        "        doa_loss_pred /= doa_loss_pred_cnt\n",
        "\n",
        "    frame_recall = good_frame_cnt / float(gt_sed.shape[0])\n",
        "    er_metric = [doa_loss_pred, frame_recall, doa_loss_pred_cnt, good_frame_cnt, more_est_cnt, less_est_cnt]\n",
        "    return er_metric\n",
        "\n",
        "\n",
        "def compute_doa_scores_clas(pred_doa_thresholded, gt_doa, data_gen_test):\n",
        "    '''\n",
        "    \"\"\"\n",
        "    The function computes DOA metrics when DOA is estimated using classification approach\n",
        "    Parameters:\n",
        "    -------------- \n",
        "    :param pred_doa_thresholded: predicted results of dimension [nb_frames, nb_classes, nb_azi*nb_ele],\n",
        "                                with value 1 when sound event active, else 0\n",
        "    :param gt_doa: reference results of dimension [nb_frames, nb_classes, nb_azi*nb_ele],\n",
        "                    with value 1 when sound event active, else 0\n",
        "    :param data_gen_test: feature or data generator class\n",
        "\n",
        "    Return:\n",
        "    ------------\n",
        "    :return er_metric: error metrics related to DOA\n",
        "    \"\"\"\n",
        "\n",
        "    '''\n",
        "    doa_loss_pred_cnt = np.sum(pred_doa_thresholded)\n",
        "\n",
        "    doa_loss_pred = 0\n",
        "    nb_good_pks = 0\n",
        "\n",
        "    less_est_cnt, less_est_frame_cnt = 0, 0\n",
        "    more_est_cnt, more_est_frame_cnt = 0, 0\n",
        "\n",
        "    for frame in range(pred_doa_thresholded.shape[0]):\n",
        "        nb_gt_peaks = int(np.sum(gt_doa[frame, :]))\n",
        "        nb_pred_peaks = int(np.sum(pred_doa_thresholded[frame, :]))\n",
        "\n",
        "        # good_frame_cnt includes frames where the nb active sources were zero in both groundtruth and prediction\n",
        "        if nb_gt_peaks == nb_pred_peaks:\n",
        "            nb_good_pks += 1\n",
        "        elif nb_gt_peaks > nb_pred_peaks:\n",
        "            less_est_frame_cnt += 1\n",
        "            less_est_cnt += (nb_gt_peaks - nb_pred_peaks)\n",
        "        elif nb_pred_peaks > nb_gt_peaks:\n",
        "            more_est_frame_cnt += 1\n",
        "            more_est_cnt += (nb_pred_peaks - nb_gt_peaks)\n",
        "\n",
        "        # when nb_ref_doa > nb_estimated_doa, ignores the extra ref doas and scores only the nearest matching doas\n",
        "        # similarly, when nb_estimated_doa > nb_ref_doa, ignores the extra estimated doa and scores the remaining matching doas\n",
        "        if nb_gt_peaks and nb_pred_peaks:\n",
        "            pred_ind = np.where(pred_doa_thresholded[frame] == 1)[1]\n",
        "            pred_list_rad = np.array(data_gen_test.get_matrix_index(pred_ind)) * np.pi / 180\n",
        "\n",
        "            gt_ind = np.where(gt_doa[frame] == 1)[1]\n",
        "            gt_list_rad = np.array(data_gen_test.get_matrix_index(gt_ind)) * np.pi / 180\n",
        "\n",
        "            frame_dist = distance_between_gt_pred(gt_list_rad.T, pred_list_rad.T)\n",
        "            doa_loss_pred += frame_dist\n",
        "\n",
        "    if doa_loss_pred_cnt:\n",
        "        doa_loss_pred /= doa_loss_pred_cnt\n",
        "\n",
        "    frame_recall = nb_good_pks / float(pred_doa_thresholded.shape[0])\n",
        "    er_metric = [doa_loss_pred, frame_recall, doa_loss_pred_cnt, nb_good_pks, more_est_cnt, less_est_cnt]\n",
        "    return er_metric\n",
        "\n",
        "\n",
        "def distance_between_gt_pred(gt_list_rad, pred_list_rad):\n",
        "    \"\"\"\n",
        "    Shortest distance between two sets of spherical coordinates. Given a set of groundtruth spherical coordinates,\n",
        "    and its respective predicted coordinates, we calculate the spherical distance between each of the spherical\n",
        "    coordinate pairs resulting in a matrix of distances, where one axis represents the number of groundtruth\n",
        "    coordinates and the other the predicted coordinates. The number of estimated peaks need not be the same as in\n",
        "    groundtruth, thus the distance matrix is not always a square matrix. We use the hungarian algorithm to find the\n",
        "    least cost in this distance matrix.\n",
        "    Parameters:\n",
        "    ---------------\n",
        "    :param gt_list_rad: list of ground-truth spherical coordinates\n",
        "    :param pred_list_rad: list of predicted spherical coordinates\n",
        "    :return: cost -  distance\n",
        "    Return:\n",
        "    ----------------\n",
        "    :return: less - number of DOA's missed\n",
        "    :return: extra - number of DOA's over-estimated\n",
        "    \"\"\"\n",
        "\n",
        "    gt_len, pred_len = gt_list_rad.shape[0], pred_list_rad.shape[0]\n",
        "    ind_pairs = np.array([[x, y] for y in range(pred_len) for x in range(gt_len)])\n",
        "    cost_mat = np.zeros((gt_len, pred_len))\n",
        "\n",
        "    # Slow implementation\n",
        "    # cost_mat = np.zeros((gt_len, pred_len))\n",
        "    # for gt_cnt, gt in enumerate(gt_list_rad):\n",
        "    #     for pred_cnt, pred in enumerate(pred_list_rad):\n",
        "    #         cost_mat[gt_cnt, pred_cnt] = distance_between_spherical_coordinates_rad(gt, pred)\n",
        "\n",
        "    # Fast implementation\n",
        "    if gt_len and pred_len:\n",
        "        az1, ele1, az2, ele2 = gt_list_rad[ind_pairs[:, 0], 0], gt_list_rad[ind_pairs[:, 0], 1], \\\n",
        "                               pred_list_rad[ind_pairs[:, 1], 0], pred_list_rad[ind_pairs[:, 1], 1]\n",
        "        cost_mat[ind_pairs[:, 0], ind_pairs[:, 1]] = distance_between_spherical_coordinates_rad(az1, ele1, az2, ele2)\n",
        "\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_mat)\n",
        "    cost = cost_mat[row_ind, col_ind].sum()\n",
        "    return cost\n",
        "\n",
        "\n",
        "def distance_between_gt_pred_xyz(gt_list, pred_list):\n",
        "    \"\"\"\n",
        "    Shortest distance between two sets of Cartesian coordinates. Given a set of groundtruth coordinates,\n",
        "    and its respective predicted coordinates, we calculate the spherical distance between each of the spherical\n",
        "    coordinate pairs resulting in a matrix of distances, where one axis represents the number of groundtruth\n",
        "    coordinates and the other the predicted coordinates. The number of estimated peaks need not be the same as in\n",
        "    groundtruth, thus the distance matrix is not always a square matrix. We use the hungarian algorithm to find the\n",
        "    least cost in this distance matrix.\n",
        "    Parameters:\n",
        "    ---------------\n",
        "    :param gt_list: list of ground-truth Cartesian coordinates\n",
        "    :param pred_list: list of predicted Cartesian coordinates\n",
        "    :return: cost -  distance\n",
        "    Return:\n",
        "    -------------\n",
        "    :return: less - number of DOA's missed\n",
        "    :return: extra - number of DOA's over-estimated\n",
        "    \"\"\"\n",
        "\n",
        "    gt_len, pred_len = gt_list.shape[0], pred_list.shape[0]\n",
        "    ind_pairs = np.array([[x, y] for y in range(pred_len) for x in range(gt_len)])\n",
        "    cost_mat = np.zeros((gt_len, pred_len))\n",
        "\n",
        "    # Slow implementation\n",
        "    # cost_mat = np.zeros((gt_len, pred_len))\n",
        "    # for gt_cnt, gt in enumerate(gt_list_rad):\n",
        "    #     for pred_cnt, pred in enumerate(pred_list_rad):\n",
        "    #         cost_mat[gt_cnt, pred_cnt] = distance_between_spherical_coordinates_rad(gt, pred)\n",
        "\n",
        "    # Fast implementation\n",
        "    if gt_len and pred_len:\n",
        "        x1, y1, z1, x2, y2, z2 = gt_list[ind_pairs[:, 0], 0], gt_list[ind_pairs[:, 0], 1], gt_list[ind_pairs[:, 0], 2], \\\n",
        "                               pred_list[ind_pairs[:, 1], 0], pred_list[ind_pairs[:, 1], 1], pred_list[ind_pairs[:, 1], 2]\n",
        "        cost_mat[ind_pairs[:, 0], ind_pairs[:, 1]] = distance_between_cartesian_coordinates(x1, y1, z1, x2, y2, z2)\n",
        "\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_mat)\n",
        "    cost = cost_mat[row_ind, col_ind].sum()\n",
        "    return cost\n",
        "\n",
        "\n",
        "def distance_between_spherical_coordinates_rad(az1, ele1, az2, ele2):\n",
        "    \"\"\"\n",
        "    The function implemenets the angukla distance between two spherical coordinates\n",
        "    MORE: https://en.wikipedia.org/wiki/Great-circle_distance\n",
        "    Parameters :\n",
        "    ---------------\n",
        "    :param az1: azimuth angle 1\n",
        "    :param az2: azimuth angle 2\n",
        "    :param ele1: elevation angle 1 \n",
        "    :param ele2: elevation angle 2\n",
        "    Return:\n",
        "    ----------------\n",
        "    :return dist: angular distance in degrees\n",
        "    \"\"\"\n",
        "    dist = np.sin(ele1) * np.sin(ele2) + np.cos(ele1) * np.cos(ele2) * np.cos(np.abs(az1 - az2))\n",
        "    # Making sure the dist values are in -1 to 1 range, else np.arccos kills the job\n",
        "    dist = np.clip(dist, -1, 1)\n",
        "    dist = np.arccos(dist) * 180 / np.pi\n",
        "    return dist\n",
        "\n",
        "\n",
        "def distance_between_cartesian_coordinates(x1, y1, z1, x2, y2, z2):\n",
        "    \"\"\"\n",
        "    The function implemenets the Angular distance between two cartesian coordinates\n",
        "    MORE: https://en.wikipedia.org/wiki/Great-circle_distance\n",
        "    Check 'From chord length' section\n",
        "    Parameters:\n",
        "    --------------- \n",
        "    :param x1, y1, z1: cartesian coordinates of first point\n",
        "    :param x2, y2, z2: cartesian coordinates of second point\n",
        "    Return:\n",
        "    --------------\n",
        "    :return dist: angular distance in degrees\n",
        "    \"\"\"\n",
        "    # Normalize the Cartesian vectors\n",
        "    N1 = np.sqrt(x1**2 + y1**2 + z1**2 + 1e-10)\n",
        "    N2 = np.sqrt(x2**2 + y2**2 + z2**2 + 1e-10)\n",
        "    x1, y1, z1, x2, y2, z2 = x1/N1, y1/N1, z1/N1, x2/N2, y2/N2, z2/N2\n",
        "\n",
        "    #Compute the distance\n",
        "    dist = x1*x2 + y1*y2 + z1*z2\n",
        "    dist = np.clip(dist, -1, 1)\n",
        "    dist = np.arccos(dist) * 180 / np.pi\n",
        "    return dist\n",
        "\n",
        "\n",
        "def sph2cart(azimuth, elevation, r):\n",
        "    '''\n",
        "    The function converts spherical to cartesian coordinates\n",
        "    Parameters:\n",
        "    ----------------\n",
        "    :param azimuth: in radians\n",
        "    :param elevation: in radians\n",
        "    :param r: in meters\n",
        "    Return:\n",
        "    ---------------\n",
        "    :return x, y, z: cartesian coordinates\n",
        "    '''\n",
        "\n",
        "    x = r * np.cos(elevation) * np.cos(azimuth)\n",
        "    y = r * np.cos(elevation) * np.sin(azimuth)\n",
        "    z = r * np.sin(elevation)\n",
        "    return x, y, z\n",
        "\n",
        "\n",
        "def cart2sph(x, y, z):\n",
        "    '''\n",
        "    The function converts cartesian to spherical coordinates\n",
        "\n",
        "    Parameters:\n",
        "    -------------\n",
        "    :param x, y and z: cartesian coordinates\n",
        "    :param y:\n",
        "    :param z:\n",
        "    Return:\n",
        "    -----------\n",
        "    :return aziazimuth, elevation: in radian\n",
        "    :return r: r in meters\n",
        "    '''\n",
        "\n",
        "    azimuth = np.arctan2(y,x)\n",
        "    elevation = np.arctan2(z,np.sqrt(x**2 + y**2))\n",
        "    r = np.sqrt(x**2 + y**2 + z**2)\n",
        "    return azimuth, elevation, r\n",
        "\n",
        "\n",
        "###############################################################\n",
        "# SELD scoring functions\n",
        "###############################################################\n",
        "\n",
        "\n",
        "def early_stopping_metric(sed_error, doa_error):\n",
        "    \"\"\"\n",
        "    The fucntion computes early stopping metric from sed and doa errors.\n",
        "    Parameter:\n",
        "    ----------------\n",
        "    :param sed_error: [error rate (0 to 1 range), f score (0 to 1 range)]\n",
        "    :param doa_error: [doa error (in degrees), frame recall (0 to 1 range)]\n",
        "    Return:\n",
        "    --------------\n",
        "    :return: seld metric result\n",
        "    \"\"\"\n",
        "    seld_metric = np.mean([\n",
        "        sed_error[0],\n",
        "        1 - sed_error[1],\n",
        "        doa_error[0]/180,\n",
        "        1 - doa_error[1]]\n",
        "        )\n",
        "    return seld_metric\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAceyAFhoDEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "eps = np.finfo(np.float).eps\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "\n",
        "\n",
        "class SeldEvaluationMetrics_SELDMetrics(object):\n",
        "    def __init__(self, doa_threshold=20, nb_classes=11):\n",
        "        '''\n",
        "        This class implements both the class-sensitive localization and location-sensitive detection metrics.\n",
        "        Additionally, based on the user input, the corresponding averaging is performed within the segment.\n",
        "        Parameters:\n",
        "        ---------------\n",
        "        :param nb_classes: Number of sound classes. \n",
        "        :param doa_thresh: DOA threshold for location sensitive detection.\n",
        "        '''\n",
        "\n",
        "        self._TP = 0\n",
        "        self._FP = 0\n",
        "        self._TN = 0\n",
        "        self._FN = 0\n",
        "\n",
        "        self._S = 0\n",
        "        self._D = 0\n",
        "        self._I = 0\n",
        "\n",
        "        self._Nref = 0\n",
        "        self._Nsys = 0\n",
        "\n",
        "        self._total_DE = 0\n",
        "        self._DE_TP = 0\n",
        "\n",
        "        self._spatial_T = doa_threshold\n",
        "        self._nb_classes = nb_classes\n",
        "\n",
        "    def compute_seld_scores(self):\n",
        "        '''\n",
        "        The function collects the final SELD scores\n",
        "        Return:\n",
        "        ---------------\n",
        "        :return: returns both location-sensitive detection scores and class-sensitive localization scores\n",
        "        '''\n",
        "\n",
        "        # Location-senstive detection performance\n",
        "        ER = (self._S + self._D + self._I) / float(self._Nref + eps)\n",
        "\n",
        "        prec = float(self._TP) / float(self._Nsys + eps)\n",
        "        recall = float(self._TP) / float(self._Nref + eps)\n",
        "        F = 2 * prec * recall / (prec + recall + eps)\n",
        "\n",
        "        # Class-sensitive localization performance\n",
        "        if self._DE_TP:\n",
        "            DE = self._total_DE / float(self._DE_TP + eps)\n",
        "        else:\n",
        "            # When the total number of prediction is zero\n",
        "            DE = 180\n",
        "\n",
        "        DE_prec = float(self._DE_TP) / float(self._Nsys + eps)\n",
        "        DE_recall = float(self._DE_TP) / float(self._Nref + eps)\n",
        "        DE_F = 2 * DE_prec * DE_recall / (DE_prec + DE_recall + eps)\n",
        "\n",
        "        return ER, F, DE, DE_F\n",
        "\n",
        "    def update_seld_scores_xyz(self, pred, gt):\n",
        "        '''\n",
        "        The fucntion implementes the spatial error averaging using Cartesian distance\n",
        "        Parameters:\n",
        "        ----------------\n",
        "        :param pred: dictionary containing class-wise prediction results for each N-seconds segment block\n",
        "        :param gt: dictionary containing class-wise groundtruth for each N-seconds segment block\n",
        "        '''\n",
        "        for block_cnt in range(len(gt.keys())):\n",
        "            loc_FN, loc_FP = 0, 0\n",
        "            for class_cnt in range(self._nb_classes):\n",
        "                # Counting the number of ref and sys outputs should include the number of tracks for each class in the segment\n",
        "                if class_cnt in gt[block_cnt]:\n",
        "                    self._Nref += 1\n",
        "                if class_cnt in pred[block_cnt]:\n",
        "                    self._Nsys += 1\n",
        "\n",
        "                if class_cnt in gt[block_cnt] and class_cnt in pred[block_cnt]:\n",
        "                    # True positives or False negative case\n",
        "\n",
        "                    # NOTE: For multiple tracks per class, identify multiple tracks using hungarian algorithm and then\n",
        "                    # calculate the spatial distance using the following code. In the current code, if there are multiple \n",
        "                    # tracks of the same class in a frame we are calculating the least cost between the groundtruth and predicted and using it.\n",
        "\n",
        "                    total_spatial_dist = 0\n",
        "                    total_framewise_matching_doa = 0\n",
        "                    gt_ind_list = gt[block_cnt][class_cnt][0][0]\n",
        "                    pred_ind_list = pred[block_cnt][class_cnt][0][0]\n",
        "                    for gt_ind, gt_val in enumerate(gt_ind_list):\n",
        "                        if gt_val in pred_ind_list:\n",
        "                            total_framewise_matching_doa += 1\n",
        "                            pred_ind = pred_ind_list.index(gt_val)\n",
        "\n",
        "                            gt_arr = np.array(gt[block_cnt][class_cnt][0][1][gt_ind])\n",
        "                            pred_arr = np.array(pred[block_cnt][class_cnt][0][1][pred_ind])\n",
        "\n",
        "                            if gt_arr.shape[0]==1 and pred_arr.shape[0]==1:\n",
        "                                total_spatial_dist += distance_between_cartesian_coordinates(gt_arr[0][0], gt_arr[0][1], gt_arr[0][2], pred_arr[0][0], pred_arr[0][1], pred_arr[0][2])\n",
        "                            else:\n",
        "                                total_spatial_dist += least_distance_between_gt_pred(gt_arr, pred_arr)\n",
        "\n",
        "                    if total_spatial_dist == 0 and total_framewise_matching_doa == 0:\n",
        "                        loc_FN += 1\n",
        "                        self._FN += 1\n",
        "                    else:\n",
        "                        avg_spatial_dist = (total_spatial_dist / total_framewise_matching_doa)\n",
        "\n",
        "                        self._total_DE += avg_spatial_dist\n",
        "                        self._DE_TP += 1\n",
        "\n",
        "                        if avg_spatial_dist <= self._spatial_T:\n",
        "                            self._TP += 1\n",
        "                        else:\n",
        "                            loc_FN += 1\n",
        "                            self._FN += 1\n",
        "                elif class_cnt in gt[block_cnt] and class_cnt not in pred[block_cnt]:\n",
        "                    # False negative\n",
        "                    loc_FN += 1\n",
        "                    self._FN += 1\n",
        "                elif class_cnt not in gt[block_cnt] and class_cnt in pred[block_cnt]:\n",
        "                    # False positive\n",
        "                    loc_FP += 1\n",
        "                    self._FP += 1\n",
        "                elif class_cnt not in gt[block_cnt] and class_cnt not in pred[block_cnt]:\n",
        "                    # True negative\n",
        "                    self._TN += 1\n",
        "\n",
        "            self._S += np.minimum(loc_FP, loc_FN)\n",
        "            self._D += np.maximum(0, loc_FN - loc_FP)\n",
        "            self._I += np.maximum(0, loc_FP - loc_FN)\n",
        "        return\n",
        "\n",
        "    def update_seld_scores(self, pred_deg, gt_deg):\n",
        "        '''\n",
        "        Thwe function implemenets the spatial error averaging using Polar distance\n",
        "        Expects the angles in degrees\n",
        "        Parameters:\n",
        "        ---------------\n",
        "        :param pred_deg: dictionary containing class-wise prediction results for each N-seconds segment block\n",
        "        :param gt_deg: dictionary containing class-wise groundtruth for each N-seconds segment block\n",
        "        '''\n",
        "        for block_cnt in range(len(gt_deg.keys())):\n",
        "            loc_FN, loc_FP = 0, 0\n",
        "            for class_cnt in range(self._nb_classes):\n",
        "                # Counting the number of ref and sys outputs should include the number of tracks for each class in the segment\n",
        "                if class_cnt in gt_deg[block_cnt]:\n",
        "                    self._Nref += 1\n",
        "                if class_cnt in pred_deg[block_cnt]:\n",
        "                    self._Nsys += 1\n",
        "\n",
        "                if class_cnt in gt_deg[block_cnt] and class_cnt in pred_deg[block_cnt]:\n",
        "                    # True positives or False negative case\n",
        "\n",
        "                    # NOTE: For multiple tracks per class, identify multiple tracks using hungarian algorithm and then\n",
        "                    # calculate the spatial distance using the following code. In the current code, if there are multiple \n",
        "                    # tracks of the same class in a frame we are calculating the least cost between the groundtruth and predicted and using it.\n",
        "                    total_spatial_dist = 0\n",
        "                    total_framewise_matching_doa = 0\n",
        "                    gt_ind_list = gt_deg[block_cnt][class_cnt][0][0]\n",
        "                    pred_ind_list = pred_deg[block_cnt][class_cnt][0][0]\n",
        "                    for gt_ind, gt_val in enumerate(gt_ind_list):\n",
        "                        if gt_val in pred_ind_list:\n",
        "                            total_framewise_matching_doa += 1\n",
        "                            pred_ind = pred_ind_list.index(gt_val)\n",
        "\n",
        "                            gt_arr = np.array(gt_deg[block_cnt][class_cnt][0][1][gt_ind]) * np.pi / 180\n",
        "                            pred_arr = np.array(pred_deg[block_cnt][class_cnt][0][1][pred_ind]) * np.pi / 180\n",
        "                            if gt_arr.shape[0]==1 and pred_arr.shape[0]==1:\n",
        "                                total_spatial_dist += distance_between_spherical_coordinates_rad(gt_arr[0][0], gt_arr[0][1], pred_arr[0][0], pred_arr[0][1])\n",
        "                            else:\n",
        "                                total_spatial_dist += least_distance_between_gt_pred(gt_arr, pred_arr)\n",
        "\n",
        "                    if total_spatial_dist == 0 and total_framewise_matching_doa == 0:\n",
        "                        loc_FN += 1\n",
        "                        self._FN += 1\n",
        "                    else:\n",
        "                        avg_spatial_dist = (total_spatial_dist / total_framewise_matching_doa)\n",
        "\n",
        "                        self._total_DE += avg_spatial_dist\n",
        "                        self._DE_TP += 1\n",
        "\n",
        "                        if avg_spatial_dist <= self._spatial_T:\n",
        "                            self._TP += 1\n",
        "                        else:\n",
        "                            loc_FN += 1\n",
        "                            self._FN += 1\n",
        "                elif class_cnt in gt_deg[block_cnt] and class_cnt not in pred_deg[block_cnt]:\n",
        "                    # False negative\n",
        "                    loc_FN += 1\n",
        "                    self._FN += 1\n",
        "                elif class_cnt not in gt_deg[block_cnt] and class_cnt in pred_deg[block_cnt]:\n",
        "                    # False positive\n",
        "                    loc_FP += 1\n",
        "                    self._FP += 1\n",
        "                elif class_cnt not in gt_deg[block_cnt] and class_cnt not in pred_deg[block_cnt]:\n",
        "                    # True negative\n",
        "                    self._TN += 1\n",
        "\n",
        "            self._S += np.minimum(loc_FP, loc_FN)\n",
        "            self._D += np.maximum(0, loc_FN - loc_FP)\n",
        "            self._I += np.maximum(0, loc_FP - loc_FN)\n",
        "        return\n",
        "\n",
        "\n",
        "def least_distance_between_gt_pred(gt_list, pred_list):\n",
        "    \"\"\"\n",
        "        Shortest distance between two sets of DOA coordinates. Given a set of groundtruth coordinates,\n",
        "        and its respective predicted coordinates, we calculate the distance between each of the \n",
        "        coordinate pairs resulting in a matrix of distances, where one axis represents the number of groundtruth\n",
        "        coordinates and the other the predicted coordinates. The number of estimated peaks need not be the same as in\n",
        "        groundtruth, thus the distance matrix is not always a square matrix. We use the hungarian algorithm to find the\n",
        "        least cost in this distance matrix.\n",
        "    Parameters:\n",
        "    --------------\n",
        "     :param gt_list_xyz: list of ground-truth Cartesian or Polar coordinates in Radians\n",
        "     :param pred_list_xyz: list of predicted Carteisan or Polar coordinates in Radians\n",
        "    Return:\n",
        "    -----------\n",
        "     :return: cost -  distance\n",
        "    \"\"\"\n",
        "    gt_len, pred_len = gt_list.shape[0], pred_list.shape[0]\n",
        "    ind_pairs = np.array([[x, y] for y in range(pred_len) for x in range(gt_len)])\n",
        "    cost_mat = np.zeros((gt_len, pred_len))\n",
        "\n",
        "    if gt_len and pred_len:\n",
        "        if len(gt_list[0]) == 3: #Cartesian\n",
        "            x1, y1, z1, x2, y2, z2 = gt_list[ind_pairs[:, 0], 0], gt_list[ind_pairs[:, 0], 1], gt_list[ind_pairs[:, 0], 2], pred_list[ind_pairs[:, 1], 0], pred_list[ind_pairs[:, 1], 1], pred_list[ind_pairs[:, 1], 2]\n",
        "            cost_mat[ind_pairs[:, 0], ind_pairs[:, 1]] = distance_between_cartesian_coordinates(x1, y1, z1, x2, y2, z2)\n",
        "        else:\n",
        "            az1, ele1, az2, ele2 = gt_list[ind_pairs[:, 0], 0], gt_list[ind_pairs[:, 0], 1], pred_list[ind_pairs[:, 1], 0], pred_list[ind_pairs[:, 1], 1]\n",
        "            cost_mat[ind_pairs[:, 0], ind_pairs[:, 1]] = distance_between_spherical_coordinates_rad(az1, ele1, az2, ele2)\n",
        "\n",
        "    row_ind, col_ind = linear_sum_assignment(cost_mat)\n",
        "    cost = cost_mat[row_ind, col_ind].sum()\n",
        "    return cost\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndRpJCUMkVXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluating the testing dataset \n",
        "for split_cnt, split in enumerate(test_splits):\n",
        "  \n",
        "  split_folder = os.path.join(output_dir, 'split_{}/'.format(split_cnt))\n",
        "  prediction_folder = os.path.join(split_folder, 'prediction_' + dataset + '/')\n",
        "  model_dir = os.path.join(split_folder, 'models/')\n",
        "  dcase_dir = os.path.join(split_folder, 'results/')\n",
        "\n",
        "  #json file to save all info in\n",
        "  datafilepath = split_folder + 'data.json'\n",
        "\n",
        "  with open(datafilepath, \"r\") as fp:\n",
        "          data = json.load(fp)\n",
        "\n",
        "  best_seld_metric = 99999\n",
        "  best_epoch = -1\n",
        "  nb_epoch = 2 if quick_test else data['epoch']  \n",
        "  print(\"Number of epoch: %s\" % (nb_epoch))\n",
        "  seld_metric = np.zeros(nb_epoch)\n",
        "  new_seld_metric = np.zeros(nb_epoch)\n",
        "  doa_metric = np.zeros((nb_epoch, 6))\n",
        "  sed_metric = np.zeros((nb_epoch, 2))\n",
        "  new_metric = np.zeros((nb_epoch, 4))\n",
        "\n",
        "  # evaluating each epoch in order to consider the best epoch and model to predict the testing dataset \n",
        "  for epoch_cnt in range(nb_epoch):\n",
        "\n",
        "    print(\"Epoch {}\".format(epoch_cnt))\n",
        "    \n",
        "    #retriving the prediction to consider the best model\n",
        "    pred_sed_filename = \"\".join(['pred_', dataset, '_sed_', str(epoch_cnt), '.npy'])\n",
        "    pred_doa_filename = \"\".join(['pred_', dataset, '_doa_', str(epoch_cnt), '.npy'])\n",
        "    sed_pred = np.load(os.path.join(prediction_folder, pred_sed_filename))\n",
        "    doa_pred = np.load(os.path.join(prediction_folder, pred_doa_filename))\n",
        "    sed_pred = reshape_3Dto2D(sed_pred) > sed_threshold\n",
        "    doa_pred = reshape_3Dto2D(doa_pred if doa_objective is 'mse' else doa_pred[:, :, nb_classes:])\n",
        "\n",
        "    # Calculate the DCASE 2019 metrics - Detection-only and Localization-only scores\n",
        "    sed_metric[epoch_cnt, :] = compute_sed_scores(sed_pred, sed_gt, data_gen_val.nb_frames_1s())\n",
        "    doa_metric[epoch_cnt, :] = compute_doa_scores_regr_xyz(doa_pred, doa_gt, sed_pred, sed_gt)\n",
        "    seld_metric[epoch_cnt] = early_stopping_metric(sed_metric[epoch_cnt, :], doa_metric[epoch_cnt, :])\n",
        "\n",
        "    # Calculate the DCASE 2020 metrics - Location-aware detection and Class-aware localization scores\n",
        "    cls_new_metric = SeldEvaluationMetrics_SELDMetrics(nb_classes=data_gen_val.get_nb_classes(), doa_threshold=lad_doa_thresh)\n",
        "\n",
        "    pred_dict = feat_cls.regression_label_format_to_output_format(sed_pred, doa_pred)\n",
        "    gt_dict = feat_cls.regression_label_format_to_output_format(sed_gt, doa_gt)\n",
        "\n",
        "    pred_blocks_dict = feat_cls.segment_labels(pred_dict, sed_pred.shape[0])\n",
        "    gt_blocks_dict = feat_cls.segment_labels(gt_dict, sed_gt.shape[0])\n",
        "\n",
        "    cls_new_metric.update_seld_scores_xyz(pred_blocks_dict, gt_blocks_dict)\n",
        "    new_metric[epoch_cnt, :] = cls_new_metric.compute_seld_scores()\n",
        "    new_seld_metric[epoch_cnt] = early_stopping_metric(new_metric[epoch_cnt, :2], new_metric[epoch_cnt, 2:])\n",
        "\n",
        "  \n",
        "    # saving the best model metric \n",
        "    if new_seld_metric[epoch_cnt] < best_seld_metric:\n",
        "      best_seld_metric = new_seld_metric[epoch_cnt]\n",
        "      best_epoch = epoch_cnt\n",
        "      model_name = '%s_model.h5' % (best_epoch)\n",
        "      best_model_path = \"\".join([model_dir, model_name])\n",
        "      \n",
        "\n",
        "    print(\n",
        "          'epoch_cnt: {}, time: {:0.2f}s,' \n",
        "          '\\n\\t\\t DCASE2019 SCORES: ER: {:0.2f}, F: {:0.1f}, DE: {:0.1f}, FR:{:0.1f}, seld_score: {:0.2f}, ' \n",
        "          '\\n\\t\\t DCASE2020 SCORES: ER: {:0.2f}, F: {:0.1f}, DE: {:0.1f}, DE_F:{:0.1f}, seld_score (early stopping score): {:0.2f}, '\n",
        "          'best_seld_score: {:0.2f}, best_epoch : {}\\n'.format(\n",
        "          epoch_cnt, time.time() - start, \n",
        "          sed_metric[epoch_cnt, 0], sed_metric[epoch_cnt, 1]*100,\n",
        "          doa_metric[epoch_cnt, 0], doa_metric[epoch_cnt, 1]*100, seld_metric[epoch_cnt],\n",
        "          new_metric[epoch_cnt, 0], new_metric[epoch_cnt, 1]*100,\n",
        "          new_metric[epoch_cnt, 2], new_metric[epoch_cnt, 3]*100,\n",
        "          new_seld_metric[epoch_cnt], best_seld_metric, best_epoch\n",
        "                  )\n",
        "              )\n",
        "\n",
        "  avg_scores_val.append([new_metric[best_epoch, 0], new_metric[best_epoch, 1], new_metric[best_epoch, 2],\n",
        "                                  new_metric[best_epoch, 3], best_seld_metric])\n",
        "\n",
        "  print('\\nResults on validation split:')\n",
        "  print('\\tUnique_name: {} '.format(best_model_path))\n",
        "  print('\\tSaved model for the best_epoch: {}'.format(best_epoch))\n",
        "  print('\\tSELD_score (early stopping score) : {}'.format(best_seld_metric))\n",
        "\n",
        "  print('\\n\\tDCASE2020 scores')\n",
        "  print('\\tClass-aware localization scores: DOA_error: {:0.1f}, F-score: {:0.1f}'.format(new_metric[best_epoch, 2], new_metric[best_epoch, 3]*100))\n",
        "  print('\\tLocation-aware detection scores: Error rate: {:0.2f}, F-score: {:0.1f}'.format(new_metric[best_epoch, 0], new_metric[best_epoch, 1]*100))\n",
        "\n",
        "  print('\\n\\tDCASE2019 scores')\n",
        "  print('\\tLocalization-only scores: DOA_error: {:0.1f}, Frame recall: {:0.1f}'.format(doa_metric[best_epoch, 0], doa_metric[best_epoch, 1]*100))\n",
        "  print('\\tDetection-only scores: Error rate: {:0.2f}, F-score: {:0.1f}\\n'.format(sed_metric[best_epoch, 0], sed_metric[best_epoch, 1]*100))\n",
        "\n",
        "     # ------------------  Calculate metric scores for unseen test split ---------------------------------\n",
        "  print('\\nLoading the best model and predicting results on the testing split')\n",
        "  print('\\tLoading testing dataset:')\n",
        "  data_gen_test = DataGenerator(\n",
        "            split=split, shuffle=False, per_file=dcase_output, is_eval=True if mode is 'eval' else False\n",
        "        )\n",
        "\n",
        "  model = load_seld_model(best_model_path, doa_objective)\n",
        "  print(\"Model loaded: {}\".format(best_model_path))\n",
        "\n",
        "  # testing dataset prediction\n",
        "  pred_test = model.predict(\n",
        "            x=data_gen_test.generate(),\n",
        "            steps=2 if quick_test else data_gen_test.get_total_batches_in_data(),\n",
        "            verbose=2\n",
        "        )\n",
        "\n",
        "  test_sed_pred = reshape_3Dto2D(pred_test[0]) > sed_threshold\n",
        "  test_doa_pred = reshape_3Dto2D(pred_test[1] if doa_objective is 'mse' else pred_test[1][:, :, nb_classes:])\n",
        "\n",
        "  if dcase_output:\n",
        "            # Dump results in DCASE output format for calculating final scores\n",
        "      dcase_dump_folder = os.path.join(dcase_dir, '{}_{}'.format(dataset, mode))\n",
        "      create_folder(dcase_dump_folder)\n",
        "      print('Dumping recording-wise results in: {}'.format(dcase_dump_folder))\n",
        "\n",
        "      test_filelist = data_gen_test.get_filelist()\n",
        "            # Number of frames for a 60 second audio with 20ms hop length = 3000 frames\n",
        "      max_frames_with_content = data_gen_test.get_nb_frames()\n",
        "\n",
        "            # Number of frames in one batch (batch_size* sequence_length) consists of all the 3000 frames above with\n",
        "            # zero padding in the remaining frames\n",
        "      frames_per_file = data_gen_test.get_frame_per_file()\n",
        "\n",
        "      for file_cnt in range(test_sed_pred.shape[0]//frames_per_file):\n",
        "          filename = test_filelist[file_cnt].split('-')[0] + '.npy'\n",
        "          output_file = os.path.join(dcase_dump_folder, filename.replace('.npy', '.csv'))\n",
        "          dc = file_cnt * frames_per_file\n",
        "          output_dict = feat_cls.regression_label_format_to_output_format(\n",
        "                    test_sed_pred[dc:dc + max_frames_with_content, :],\n",
        "                    test_doa_pred[dc:dc + max_frames_with_content, :]\n",
        "                )\n",
        "          data_gen_test.write_output_format_file(output_file, output_dict)\n",
        "\n",
        "  if mode is 'dev':\n",
        "\n",
        "    test_data_in, test_data_out = data_gen_test.get_data_sizes()\n",
        "    test_gt = collect_test_labels(data_gen_test, test_data_out, nb_classes, quick_test)\n",
        "    test_sed_gt = reshape_3Dto2D(test_gt[0])\n",
        "    test_doa_gt = reshape_3Dto2D(test_gt[1])\n",
        "         \n",
        "    # Calculate DCASE2019 scores\n",
        "    test_sed_loss = compute_sed_scores(test_sed_pred, test_sed_gt, data_gen_test.nb_frames_1s())\n",
        "    test_doa_loss = compute_doa_scores_regr_xyz(test_doa_pred, test_doa_gt, test_sed_pred, test_sed_gt)\n",
        "    test_metric_loss = early_stopping_metric(test_sed_loss, test_doa_loss)\n",
        "\n",
        "    # Calculate DCASE2020 scores\n",
        "    cls_new_metric = SeldEvaluationMetrics_SELDMetrics(nb_classes=data_gen_test.get_nb_classes(), doa_threshold=lad_doa_thresh)\n",
        "    test_pred_dict = feat_cls.regression_label_format_to_output_format(\n",
        "            test_sed_pred, test_doa_pred\n",
        "        )\n",
        "    test_gt_dict = feat_cls.regression_label_format_to_output_format(\n",
        "            test_sed_gt, test_doa_gt\n",
        "      )\n",
        "\n",
        "    test_pred_blocks_dict = feat_cls.segment_labels(test_pred_dict, test_sed_pred.shape[0])\n",
        "    test_gt_blocks_dict = feat_cls.segment_labels(test_gt_dict, test_sed_gt.shape[0])\n",
        "\n",
        "    cls_new_metric.update_seld_scores_xyz(test_pred_blocks_dict, test_gt_blocks_dict)\n",
        "    test_new_metric = cls_new_metric.compute_seld_scores()\n",
        "    test_new_seld_metric = early_stopping_metric(test_new_metric[:2], test_new_metric[2:])\n",
        "\n",
        "    avg_scores_test.append([test_new_metric[0], test_new_metric[1], test_new_metric[2], test_new_metric[3], test_new_seld_metric])\n",
        "    print('Results on test split:')\n",
        "\n",
        "    print('\\tDCASE2020 Scores')\n",
        "    print('\\tClass-aware localization scores: DOA Error: {:0.1f}, F-score: {:0.1f}'.format(test_new_metric[2], test_new_metric[3]*100))\n",
        "    print('\\tLocation-aware detection scores: Error rate: {:0.2f}, F-score: {:0.1f}'.format(test_new_metric[0], test_new_metric[1]*100))\n",
        "    print('\\tSELD (early stopping metric): {:0.2f}'.format(test_new_seld_metric))\n",
        "\n",
        "    print('\\n\\tDCASE2019 Scores')\n",
        "    print('\\tLocalization-only scores: DOA Error: {:0.1f}, Frame recall: {:0.1f}'.format(test_doa_loss[0], test_doa_loss[1]*100))\n",
        "    print('\\tDetection-only scores:Error rate: {:0.2f}, F-score: {:0.1f}'.format(test_sed_loss[0], test_sed_loss[1]*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bINjWWu0uAZX",
        "colab_type": "text"
      },
      "source": [
        "## Validation and Testing loss\n",
        "\n",
        "All the information related to training and validation loss are retrieved so to evaluate overfitting. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQjz4Vvfqbje",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import ast \n",
        "split_folder = os.path.join(output_dir, 'split_{}'.format(0))\n",
        "datafilepath = split_folder + '/data.json'\n",
        "history_folder = os.path.join(split_folder, 'history/')\n",
        "\n",
        "loss = []\n",
        "sed_out_loss = []\n",
        "doa_out_loss = []\n",
        "val_loss = []\n",
        "sed_out_val_loss = []\n",
        "doa_out_val_loss = []\n",
        "\n",
        "with open(datafilepath) as fp:\n",
        "  data = json.load(fp)\n",
        "\n",
        "nb_epoch = data['epoch']\n",
        "\n",
        "# plotting validation and training loss to evaluate the overfitting \n",
        "for epoch_cnt in range(nb_epoch):\n",
        "  hist_loss_filename = os.path.join(\"\".join([history_folder, 'pred_%s_%s_hist_loss.json' % (dataset, str(epoch_cnt))]))\n",
        "  with open(hist_loss_filename) as fp:\n",
        "    hist_loss = json.load(fp)\n",
        "    hist_loss = ast.literal_eval(hist_loss) \n",
        "    if len(loss) == 0:\n",
        "      loss = hist_loss['loss']\n",
        "      sed_out_loss = hist_loss['sed_out_loss']\n",
        "      doa_out_loss = hist_loss['doa_out_loss']\n",
        "      val_loss = hist_loss['val_loss']\n",
        "      sed_out_val_loss = hist_loss['val_sed_out_loss']\n",
        "      doa_out_val_loss = hist_loss['val_doa_out_loss']\n",
        "    else:\n",
        "      loss.append(hist_loss['loss'][0])\n",
        "      sed_out_loss.append(hist_loss['sed_out_loss'][0])\n",
        "      doa_out_loss.append(hist_loss['doa_out_loss'][0])\n",
        "      val_loss.append(hist_loss['val_loss'][0])\n",
        "      sed_out_val_loss.append(hist_loss['val_sed_out_loss'][0])\n",
        "      doa_out_val_loss.append(hist_loss['val_doa_out_loss'][0])\n",
        "\n",
        "\n",
        "plt.figure(figsize=(22, 5))\n",
        "plt.plot(loss)\n",
        "plt.plot(sed_out_loss)\n",
        "plt.plot(doa_out_loss)\n",
        "plt.plot(val_loss)\n",
        "plt.plot(sed_out_val_loss)\n",
        "plt.plot(doa_out_val_loss)\n",
        "plt.title('Model loss: {}, nb epoch: {}'.format(network, nb_epoch))\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['loss', 'sed_loss', 'doa_loss', 'val_loss', 'val_sed_out_loss', 'val_doa_out_loss'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}